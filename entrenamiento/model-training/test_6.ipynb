{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 6 (paper) - Experimento 4 (PT)\n",
    "\n",
    "Entrenamiento de Mask R-CNN con dataset modificado para emular \"Test 6\"\n",
    "\n",
    "### Hiperparametros\n",
    "* **epoch = 100**\n",
    "    * steps x epoch = 146 (lotes de imagenes)\n",
    "    * batch = 2\n",
    "* optimizador = SGD\n",
    "* Funcion de perdida = SMOOTHL1LOSS\n",
    "* Metrica de evaluacion = mAP (IoU >= 0.5)\n",
    "* Mini-mask shape: 56x56\n",
    "* RPN anchor scales: (32, 64, 128, 256, 512)\n",
    "* Tasa de aprendizaje: 0.001\n",
    "* imagenes = 292\n",
    "    * entrenamiento 81% = 237\n",
    "    * validacion 19% = 55\n",
    "* etiquetas = 9140\n",
    "* **resolucion = 1024 x 800**\n",
    "* etiquetas = bounding box formato VOC XML\n",
    "* numero de clases = 1 (arandano)\n",
    "* **data augmentation = true**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9csYdOiCeux-"
   },
   "source": [
    "## Comprobar directorio principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/PT_JoseVeloso/Mask_RCNN-master_matterport/model-training\r\n",
      "total 1528\r\n",
      "drwxr-xr-x 4 root root   4096 Aug  7 06:10 build\r\n",
      "drwxr-xr-x 2 root root   4096 Aug  7 06:10 dist\r\n",
      "drwxr-xr-x 2 root root   4096 Aug  8 03:15 mask_rcnn.egg-info\r\n",
      "-rw-r--r-- 1 root root  67789 Sep 16 23:55 master-test_11.ipynb\r\n",
      "-rw-r--r-- 1 root root  88232 Sep 17 07:27 master-test_11_fase_2-Copy1.ipynb\r\n",
      "-rw-r--r-- 1 root root  67792 Sep 17 08:36 master-test_11_fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root  30144 Sep 16 23:44 master-test_12.ipynb\r\n",
      "-rw-r--r-- 1 root root  30144 Sep 16 22:02 master-test_12_fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 350337 Sep 15 00:38 master-test_5-fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 350144 Sep 17 08:42 master-test_5_fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 110377 Sep 17 16:09 master-test_6.ipynb\r\n",
      "-rw-r--r-- 1 root root 270148 Sep 17 16:09 master-test_6_fase_2.ipynb\r\n",
      "drwxr-xr-x 4 root root   4096 Sep 13 07:49 mrcnn\r\n",
      "drwxr-xr-x 3 root root   4096 Sep 15 02:27 old\r\n",
      "-rw-r--r-- 1 root root 163666 Sep 18 15:38 test_5_corregido.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!pwd && ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6qajN7v0saE"
   },
   "source": [
    "# Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6812,
     "status": "ok",
     "timestamp": 1659596011947,
     "user": {
      "displayName": "José Ignacio Veloso Inzunza",
      "userId": "04140603416196179882"
     },
     "user_tz": 240
    },
    "id": "iyA_0ghC0saJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bibliotecas basicas\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "#sys.path.append(\"/tf/PT_JoseVeloso/Mask_RCNN-master/\")\n",
    "\n",
    "# bibliotecas avanzadas \n",
    "from xml.etree import ElementTree\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import imgaug\n",
    "\n",
    "# bibliotecas mask rcnn \n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn import visualize\n",
    "\n",
    "# biblioteca matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# bibliotecas numpy \n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "\n",
    "# bibliotecas keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img   #keras.preprocessing.image tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# ignorar alertas de elementos que seran descontinuados\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "%matplotlib inline\n",
    "#plt.show()\n",
    "\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Mbj3-t70saL"
   },
   "source": [
    "# Entrenamiento con una sola clase y etiquetas de Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGtz-ovS0saM"
   },
   "source": [
    "En este entremamiento se utiliza un conjunto de datos simple con imágenes etiquetadas con cuadros delimitadores y una clase llamada 'Daño'. En la siguiente sección se encuentra el código para el entrenamiento del modelo. Se incluyen comentarios para describir mejor el flujo del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetArandanos(Dataset):\n",
    "    \n",
    "    # la funcion load_dataset es usada para cargar el dataset de entrenamiento y test\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        \n",
    "        # se agrega una clase que se necesita para clasificar, en este caso arandano\n",
    "        self.add_class(\"dataset\", 1, \"arandano\")\n",
    "        \n",
    "        # se concatena dataset_dir con /images y /annots\n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annots/'\n",
    "        \n",
    "        # is_train sera Verdadero si se esta entrenando el modelo y Falso si se esta testeando el modelo\n",
    "        for filename in listdir(images_dir):\n",
    "            \n",
    "            # extraer image id\n",
    "            image_id = filename[:-4] # se usa para omitir los últimos 4 caracteres: '.jpg' (en class_id.jpg)\n",
    "            \n",
    "            # si is_train es Verdadero se omiten todas las imágenes con id mayor que e iguales a 11074\n",
    "            # aproximadamente el 80% del conjunto de datos es para entrenamiento\n",
    "            \n",
    "            if is_train and int(image_id) >= 41590 :\n",
    "                #vprint(\"image_id: \", image_id)\n",
    "                continue\n",
    "            \n",
    "            # si is_train no es Verdadero se omiten todas las imágenes con id menores a 11074\n",
    "            if not is_train and int(image_id) < 41590:\n",
    "                continue\n",
    "            \n",
    "            # se declara la ruta de la imagen y la ruta de las etiquetas \n",
    "            img_path = images_dir + filename\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            \n",
    "            # usando la función add_image se pasan image_id, image_path y ann_path para que la \n",
    "            # imagen actual se agregue al conjunto de datos para entrenamiento o prueba\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "    # funcino usada para extraer bouding boxes desde archivos etiquetados \n",
    "    def extract_boxes(self, filename):\n",
    "\n",
    "        # se puede ver en las imágenes que estan etiquetadas, como se extraen los valores de ancho, alto y bndbox\n",
    "        \n",
    "        # <annotation>\n",
    "        # <size>\n",
    "\n",
    "        #       <width>640</width>\n",
    "\n",
    "        #       <height>360</height>\n",
    "\n",
    "        #       <depth>3</depth>\n",
    "\n",
    "        # </size>\n",
    "\n",
    "\n",
    "        # <object>\n",
    "\n",
    "        #          <name>damage</name>\n",
    "\n",
    "        #          <pose>Unspecified</pose>\n",
    "\n",
    "        #          <truncated>0</truncated>\n",
    "\n",
    "        #          <difficult>0</difficult>\n",
    "\n",
    "\n",
    "        #          <bndbox>\n",
    "\n",
    "        #                 <xmin>315</xmin>\n",
    "\n",
    "        #                 <ymin>160</ymin>\n",
    "\n",
    "        #                 <xmax>381</xmax>\n",
    "\n",
    "        #                 <ymax>199</ymax>\n",
    "\n",
    "        #          </bndbox>\n",
    "\n",
    "        # </object>\n",
    "        # </annotation>\n",
    "        \n",
    "        # para analizar los archivos .xml\n",
    "        tree = ElementTree.parse(filename)\n",
    "        \n",
    "        # para obtener la raíz del archivo xml\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # se agregan todas las coordenadas x, y en boxes para todas las instancias de un objeto\n",
    "        boxes = list()\n",
    "        \n",
    "        # se encuentran todos los atributos con el nombre bndbox que existan para cada ground truth en la imagen\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(coors)\n",
    "        \n",
    "        # extraer ancho y alto de la imagen\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        \n",
    "        # retorna boxes-> list, width-> int y height-> int \n",
    "        return boxes, width, height\n",
    "    \n",
    "    # this function calls on the extract_boxes method and is used to load a mask for each instance in an image\n",
    "    # returns a boolean mask with following dimensions width * height * instances\n",
    "\n",
    "    # esta función llama al método extract_boxes y se usa para cargar una máscara para cada instancia en una imagen \n",
    "    # devuelve una máscara booleana con las siguientes dimensiones ancho * alto * instancias\n",
    "    def load_mask(self, image_id):\n",
    "        \n",
    "        # info apunta al image_id actual \n",
    "        info = self.image_info[image_id]\n",
    "        \n",
    "        # se obtiene la ruta de anotación de image_id que es dataset_dir/annots/image_id.xml \n",
    "        path = info['annotation']\n",
    "        \n",
    "        # se llama al método extract_boxes (arriba) para obtener bndbox del archivo .xml\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        \n",
    "        # se crea una cantidad de len(boxes) de mascaras de alto 'h' y ancho 'w'\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        \n",
    "        # se agrega (append) el class_id 1 para arandano en nuestro caso a la variable\n",
    "        class_ids = list()\n",
    "        \n",
    "        # se recorren todos los boxes y generamos máscaras (máscara de bndbox) y class id para cada instancia\n",
    "        # las máscaras tendrán forma rectangular ya que hemos usado bndboxes para etiquetas\n",
    "        # por ejemplo: si 2.jpg tiene tres objetos, tendremos las siguientes máscaras y class_ids.\n",
    "\n",
    "        # 000000000 000000000 000001110 \n",
    "        # 000011100 011100000 000001110\n",
    "        # 000011100 011100000 000001110\n",
    "        # 000000000 011100000 000000000\n",
    "        #    1         1          1    <- class_ids\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index('arandano'))\n",
    "        \n",
    "        # retorna mascaras y class_ids como arreglo\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "    \n",
    "    # esta funciones toma el image_id y retorna la ruta de la imagen \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DEVICE                         /gpu:0\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.8\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           arandano_cfg\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 1.5]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                146\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "Train_ROIs_Per_Image           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# clase de configuracion arandano, aqui se pueden cambiar valores de hyper parameters \n",
    "class ConfigArandanos(Config):\n",
    "\n",
    "    # nombre de la configuracion \n",
    "    NAME = \"arandano_cfg_6\"    \n",
    "    \n",
    "    # clase arandano + clase background \n",
    "    NUM_CLASSES = 1 + 1\n",
    "    \n",
    "    # pasos por epoch y confianza minima    # STEPS_PER_EPOCH = cantidad de lotes/batchs\n",
    "    #STEPS_PER_EPOCH = 73   # por epoch se entrenaran 73 lotes de 4 imagenes, dataset = 292\n",
    "    STEPS_PER_EPOCH = 146\n",
    "    \n",
    "    # tasa de aprendizaje y momentum\n",
    "    LEARNING_RATE=0.001\n",
    "    LEARNING_MOMENTUM = 0.8\n",
    "    \n",
    "    # penalización de regularización\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    \n",
    "    # el tamaño de la imagen está controlado por este parámetro\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    \n",
    "    # pasos de validación\n",
    "    VALIDATION_STEPS = 50\n",
    "    \n",
    "    # número de regiones de interés generadas por imagen\n",
    "    Train_ROIs_Per_Image = 200\n",
    "    \n",
    "    # escala de anclas RPN y proporciones (ratios) para encontrar la ROI\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)    # Longitud del lado del ancla cuadrada, en píxeles \n",
    "    RPN_ANCHOR_RATIOS = [0.5, 1, 1.5]   # Proporciones de anclas por cada celda (ancho/alto). Un valor de 1 representa un ancla cuadrada y 0,5 es un ancla ancha \n",
    "    \n",
    "    #DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0    \n",
    "    DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "ConfigArandanos().display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/PT_JoseVeloso/Mask_RCNN-master_matterport\n"
     ]
    }
   ],
   "source": [
    "cd /tf/PT_JoseVeloso/Mask_RCNN-master_matterport/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pesos = 'mask_rcnn_coco.h5'\n",
    "#pesos = 'mask_rcnn_damage_cfg_0049.h5'\n",
    "#pesos = 'arandano_cfg_test_5_20220907T0914/mask_rcnn_arandano_cfg_0300.h5'\n",
    "pesos = 'arandano_cfg20220907T0914/mask_rcnn_arandano_cfg_0300.h5'\n",
    "\n",
    "conjunto_datos = 'customImages/test_6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3787125,
     "status": "ok",
     "timestamp": 1659604139130,
     "user": {
      "displayName": "José Ignacio Veloso Inzunza",
      "userId": "04140603416196179882"
     },
     "user_tz": 240
    },
    "id": "dF77APDH0saM",
    "outputId": "aa2a0330-e201-4b00-b12c-fee7986449cb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id:  31102\n",
      "image_id:  40099\n",
      "image_id:  30377\n",
      "image_id:  40414\n",
      "image_id:  21130\n",
      "image_id:  50469\n",
      "image_id:  41732\n",
      "image_id:  25544\n",
      "image_id:  50458\n",
      "image_id:  23863\n",
      "image_id:  30990\n",
      "image_id:  30470\n",
      "image_id:  20318\n",
      "image_id:  50440\n",
      "image_id:  21295\n",
      "image_id:  22345\n",
      "image_id:  40390\n",
      "image_id:  20782\n",
      "image_id:  30676\n",
      "image_id:  30000\n",
      "image_id:  50135\n",
      "image_id:  50912\n",
      "image_id:  22783\n",
      "image_id:  20150\n",
      "image_id:  40346\n",
      "image_id:  31246\n",
      "image_id:  25750\n",
      "image_id:  50983\n",
      "image_id:  50607\n",
      "image_id:  25690\n",
      "image_id:  40999\n",
      "image_id:  21150\n",
      "image_id:  23719\n",
      "image_id:  11117\n",
      "image_id:  20425\n",
      "image_id:  40253\n",
      "image_id:  51082\n",
      "image_id:  20250\n",
      "image_id:  41406\n",
      "image_id:  20585\n",
      "image_id:  11076\n",
      "image_id:  50393\n",
      "image_id:  30851\n",
      "image_id:  50958\n",
      "image_id:  50857\n",
      "image_id:  25640\n",
      "image_id:  51057\n",
      "image_id:  50710\n",
      "image_id:  31284\n",
      "image_id:  40213\n",
      "image_id:  40960\n",
      "image_id:  50386\n",
      "image_id:  41762\n",
      "image_id:  41383\n",
      "image_id:  22536\n",
      "image_id:  30502\n",
      "image_id:  50269\n",
      "image_id:  30958\n",
      "image_id:  22218\n",
      "image_id:  11081\n",
      "image_id:  41535\n",
      "image_id:  40393\n",
      "image_id:  25808\n",
      "image_id:  40299\n",
      "image_id:  11077\n",
      "image_id:  25817\n",
      "image_id:  25555\n",
      "image_id:  30641\n",
      "image_id:  21680\n",
      "image_id:  31040\n",
      "image_id:  20800\n",
      "image_id:  40379\n",
      "image_id:  51076\n",
      "image_id:  20988\n",
      "image_id:  50000\n",
      "image_id:  23550\n",
      "image_id:  23361\n",
      "image_id:  50653\n",
      "image_id:  40811\n",
      "image_id:  21320\n",
      "image_id:  11083\n",
      "image_id:  21942\n",
      "image_id:  41590\n",
      "image_id:  22075\n",
      "image_id:  40117\n",
      "image_id:  22710\n",
      "image_id:  50358\n",
      "image_id:  30262\n",
      "image_id:  25535\n",
      "image_id:  21555\n",
      "image_id:  50371\n",
      "image_id:  21217\n",
      "image_id:  40633\n",
      "image_id:  11088\n",
      "image_id:  22265\n",
      "image_id:  21405\n",
      "image_id:  50298\n",
      "image_id:  50206\n",
      "image_id:  50516\n",
      "image_id:  30866\n",
      "image_id:  23116\n",
      "image_id:  11074\n",
      "image_id:  50806\n",
      "image_id:  20540\n",
      "image_id:  23340\n",
      "image_id:  11080\n",
      "image_id:  22117\n",
      "image_id:  50980\n",
      "image_id:  23469\n",
      "image_id:  40205\n",
      "image_id:  30580\n",
      "image_id:  30985\n",
      "image_id:  11087\n",
      "image_id:  50582\n",
      "image_id:  50111\n",
      "image_id:  30842\n",
      "image_id:  30944\n",
      "image_id:  21177\n",
      "image_id:  11085\n",
      "image_id:  40796\n",
      "image_id:  40450\n",
      "image_id:  11079\n",
      "image_id:  25460\n",
      "image_id:  50544\n",
      "image_id:  40000\n",
      "image_id:  22851\n",
      "image_id:  41236\n",
      "image_id:  11089\n",
      "image_id:  41780\n",
      "image_id:  51230\n",
      "image_id:  23835\n",
      "image_id:  50281\n",
      "image_id:  22420\n",
      "image_id:  30533\n",
      "image_id:  31210\n",
      "image_id:  30732\n",
      "image_id:  41893\n",
      "image_id:  21960\n",
      "image_id:  30602\n",
      "image_id:  41299\n",
      "image_id:  50630\n",
      "image_id:  50232\n",
      "image_id:  20650\n",
      "image_id:  50404\n",
      "image_id:  20375\n",
      "image_id:  40428\n",
      "image_id:  23261\n",
      "image_id:  41657\n",
      "image_id:  41208\n",
      "image_id:  11082\n",
      "image_id:  22520\n",
      "image_id:  21050\n",
      "image_id:  51115\n",
      "image_id:  20495\n",
      "image_id:  50665\n",
      "image_id:  51160\n",
      "image_id:  40720\n",
      "image_id:  40684\n",
      "image_id:  25283\n",
      "image_id:  40653\n",
      "image_id:  30924\n",
      "image_id:  30225\n",
      "image_id:  25450\n",
      "image_id:  21085\n",
      "image_id:  11090\n",
      "image_id:  22603\n",
      "image_id:  50479\n",
      "image_id:  21158\n",
      "image_id:  30948\n",
      "image_id:  30111\n",
      "image_id:  51187\n",
      "image_id:  50764\n",
      "image_id:  40511\n",
      "image_id:  11078\n",
      "image_id:  51002\n",
      "image_id:  22652\n",
      "image_id:  25457\n",
      "image_id:  23084\n",
      "image_id:  31109\n",
      "image_id:  41917\n",
      "image_id:  22760\n",
      "image_id:  22175\n",
      "image_id:  20000\n",
      "image_id:  41215\n",
      "image_id:  22634\n",
      "image_id:  30400\n",
      "image_id:  20969\n",
      "image_id:  50658\n",
      "image_id:  11086\n",
      "image_id:  30439\n",
      "image_id:  50616\n",
      "image_id:  11075\n",
      "image_id:  50127\n",
      "image_id:  31148\n",
      "image_id:  50191\n",
      "image_id:  22365\n",
      "image_id:  23650\n",
      "image_id:  25502\n",
      "image_id:  30587\n",
      "image_id:  23017\n",
      "image_id:  41474\n",
      "image_id:  41009\n",
      "image_id:  21145\n",
      "image_id:  50219\n",
      "image_id:  23245\n",
      "image_id:  22771\n",
      "image_id:  30831\n",
      "image_id:  41069\n",
      "image_id:  23095\n",
      "image_id:  41749\n",
      "image_id:  21000\n",
      "image_id:  30816\n",
      "image_id:  22311\n",
      "image_id:  30350\n",
      "image_id:  50985\n",
      "image_id:  25490\n",
      "image_id:  40587\n",
      "image_id:  25623\n",
      "image_id:  50642\n",
      "image_id:  22930\n",
      "image_id:  50239\n",
      "image_id:  20930\n",
      "image_id:  30189\n",
      "image_id:  40568\n",
      "image_id:  20750\n",
      "image_id:  21717\n",
      "image_id:  30780\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./arandano_cfg20220912T1950/mask_rcnn_arandano_cfg_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32, device=/device:GPU:0))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32, device=/device:GPU:0))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 57) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/146 [..............................] - ETA: 2:08 - batch: 1.0000 - size: 2.0000 - loss: 37.3243 - rpn_class_loss: 16.9747 - rpn_bbox_loss: 20.3495 - mrcnn_class_loss: 1.3448e-04 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 57) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21/146 [===>..........................] - ETA: 1:07 - batch: 10.0000 - size: 2.0000 - loss: 21.7648 - rpn_class_loss: 6.7359 - rpn_bbox_loss: 11.5561 - mrcnn_class_loss: 0.0362 - mrcnn_bbox_loss: 3.1108 - mrcnn_mask_loss: 0.3257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/146 [====>.........................] - ETA: 1:02 - batch: 14.0000 - size: 2.0000 - loss: 21.3565 - rpn_class_loss: 5.7839 - rpn_bbox_loss: 11.5519 - mrcnn_class_loss: 0.0404 - mrcnn_bbox_loss: 3.6432 - mrcnn_mask_loss: 0.3371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/146 [======>.......................] - ETA: 1:00 - batch: 17.5000 - size: 2.0000 - loss: 20.3216 - rpn_class_loss: 5.0422 - rpn_bbox_loss: 10.9688 - mrcnn_class_loss: 0.0433 - mrcnn_bbox_loss: 3.9183 - mrcnn_mask_loss: 0.3489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50/146 [=========>....................] - ETA: 1:02 - batch: 24.5000 - size: 2.0000 - loss: 19.2834 - rpn_class_loss: 4.0998 - rpn_bbox_loss: 10.5599 - mrcnn_class_loss: 0.0455 - mrcnn_bbox_loss: 4.2301 - mrcnn_mask_loss: 0.3481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58/146 [==========>...................] - ETA: 1:01 - batch: 28.5000 - size: 2.0000 - loss: 19.0976 - rpn_class_loss: 3.7352 - rpn_bbox_loss: 10.5559 - mrcnn_class_loss: 0.0496 - mrcnn_bbox_loss: 4.3956 - mrcnn_mask_loss: 0.3614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/146 [===========>..................] - ETA: 1:01 - batch: 30.0000 - size: 2.0000 - loss: 18.7894 - rpn_class_loss: 3.6472 - rpn_bbox_loss: 10.4196 - mrcnn_class_loss: 0.0481 - mrcnn_bbox_loss: 4.3100 - mrcnn_mask_loss: 0.3645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 36) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 62/146 [===========>..................] - ETA: 1:00 - batch: 30.5000 - size: 2.0000 - loss: 18.6855 - rpn_class_loss: 3.6039 - rpn_bbox_loss: 10.3539 - mrcnn_class_loss: 0.0485 - mrcnn_bbox_loss: 4.3126 - mrcnn_mask_loss: 0.3665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69/146 [=============>................] - ETA: 56s - batch: 34.0000 - size: 2.0000 - loss: 18.0356 - rpn_class_loss: 3.3659 - rpn_bbox_loss: 9.8856 - mrcnn_class_loss: 0.0527 - mrcnn_bbox_loss: 4.3539 - mrcnn_mask_loss: 0.3774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 36) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 70/146 [=============>................] - ETA: 56s - batch: 34.5000 - size: 2.0000 - loss: 17.9154 - rpn_class_loss: 3.3306 - rpn_bbox_loss: 9.8245 - mrcnn_class_loss: 0.0547 - mrcnn_bbox_loss: 4.3262 - mrcnn_mask_loss: 0.3794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 36) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74/146 [==============>...............] - ETA: 54s - batch: 36.5000 - size: 2.0000 - loss: 17.3999 - rpn_class_loss: 3.1941 - rpn_bbox_loss: 9.5276 - mrcnn_class_loss: 0.0590 - mrcnn_bbox_loss: 4.2338 - mrcnn_mask_loss: 0.3853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 60) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76/146 [==============>...............] - ETA: 54s - batch: 37.5000 - size: 2.0000 - loss: 17.2615 - rpn_class_loss: 3.1649 - rpn_bbox_loss: 9.4118 - mrcnn_class_loss: 0.0595 - mrcnn_bbox_loss: 4.2363 - mrcnn_mask_loss: 0.3890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 77/146 [==============>...............] - ETA: 53s - batch: 38.0000 - size: 2.0000 - loss: 17.1552 - rpn_class_loss: 3.1327 - rpn_bbox_loss: 9.3500 - mrcnn_class_loss: 0.0589 - mrcnn_bbox_loss: 4.2233 - mrcnn_mask_loss: 0.3902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 78/146 [===============>..............] - ETA: 53s - batch: 38.5000 - size: 2.0000 - loss: 17.0968 - rpn_class_loss: 3.1025 - rpn_bbox_loss: 9.3002 - mrcnn_class_loss: 0.0594 - mrcnn_bbox_loss: 4.2434 - mrcnn_mask_loss: 0.3913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82/146 [===============>..............] - ETA: 50s - batch: 40.5000 - size: 2.0000 - loss: 16.6660 - rpn_class_loss: 3.0070 - rpn_bbox_loss: 9.0706 - mrcnn_class_loss: 0.0590 - mrcnn_bbox_loss: 4.1370 - mrcnn_mask_loss: 0.3924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 36) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 83/146 [================>.............] - ETA: 49s - batch: 41.0000 - size: 2.0000 - loss: 16.5661 - rpn_class_loss: 2.9807 - rpn_bbox_loss: 9.0072 - mrcnn_class_loss: 0.0600 - mrcnn_bbox_loss: 4.1224 - mrcnn_mask_loss: 0.3958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 60) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 84/146 [================>.............] - ETA: 50s - batch: 41.5000 - size: 2.0000 - loss: 16.4938 - rpn_class_loss: 2.9647 - rpn_bbox_loss: 8.9758 - mrcnn_class_loss: 0.0606 - mrcnn_bbox_loss: 4.0950 - mrcnn_mask_loss: 0.3977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/146 [=================>............] - ETA: 45s - batch: 45.0000 - size: 2.0000 - loss: 15.9372 - rpn_class_loss: 2.8125 - rpn_bbox_loss: 8.6836 - mrcnn_class_loss: 0.0643 - mrcnn_bbox_loss: 3.9676 - mrcnn_mask_loss: 0.4093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 92/146 [=================>............] - ETA: 44s - batch: 45.5000 - size: 2.0000 - loss: 15.8547 - rpn_class_loss: 2.8043 - rpn_bbox_loss: 8.6575 - mrcnn_class_loss: 0.0636 - mrcnn_bbox_loss: 3.9244 - mrcnn_mask_loss: 0.4048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/146 [==================>...........] - ETA: 41s - batch: 47.5000 - size: 2.0000 - loss: 15.5256 - rpn_class_loss: 2.7370 - rpn_bbox_loss: 8.4802 - mrcnn_class_loss: 0.0637 - mrcnn_bbox_loss: 3.8420 - mrcnn_mask_loss: 0.4027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 57) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/146 [===================>..........] - ETA: 38s - batch: 49.5000 - size: 2.0000 - loss: 15.2563 - rpn_class_loss: 2.6673 - rpn_bbox_loss: 8.3428 - mrcnn_class_loss: 0.0637 - mrcnn_bbox_loss: 3.7756 - mrcnn_mask_loss: 0.4070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/146 [====================>.........] - ETA: 32s - batch: 53.0000 - size: 2.0000 - loss: 14.9306 - rpn_class_loss: 2.5754 - rpn_bbox_loss: 8.1769 - mrcnn_class_loss: 0.0689 - mrcnn_bbox_loss: 3.6992 - mrcnn_mask_loss: 0.4103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 36) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/146 [=====================>........] - ETA: 29s - batch: 55.0000 - size: 2.0000 - loss: 14.6877 - rpn_class_loss: 2.5156 - rpn_bbox_loss: 8.0378 - mrcnn_class_loss: 0.0704 - mrcnn_bbox_loss: 3.6505 - mrcnn_mask_loss: 0.4136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 60) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/146 [======================>.......] - ETA: 27s - batch: 56.5000 - size: 2.0000 - loss: 14.5143 - rpn_class_loss: 2.4760 - rpn_bbox_loss: 7.9527 - mrcnn_class_loss: 0.0711 - mrcnn_bbox_loss: 3.5994 - mrcnn_mask_loss: 0.4151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/146 [=======================>......] - ETA: 23s - batch: 59.0000 - size: 2.0000 - loss: 14.1616 - rpn_class_loss: 2.4045 - rpn_bbox_loss: 7.7529 - mrcnn_class_loss: 0.0745 - mrcnn_bbox_loss: 3.5104 - mrcnn_mask_loss: 0.4194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 60) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/146 [=========================>....] - ETA: 16s - batch: 63.0000 - size: 2.0000 - loss: 13.6434 - rpn_class_loss: 2.3142 - rpn_bbox_loss: 7.4469 - mrcnn_class_loss: 0.0800 - mrcnn_bbox_loss: 3.3774 - mrcnn_mask_loss: 0.4250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "128/146 [=========================>....] - ETA: 16s - batch: 63.5000 - size: 2.0000 - loss: 13.5780 - rpn_class_loss: 2.3022 - rpn_bbox_loss: 7.4083 - mrcnn_class_loss: 0.0815 - mrcnn_bbox_loss: 3.3604 - mrcnn_mask_loss: 0.4256"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/146 [===========================>..] - ETA: 8s - batch: 68.0000 - size: 2.0000 - loss: 13.0357 - rpn_class_loss: 2.2044 - rpn_bbox_loss: 7.0886 - mrcnn_class_loss: 0.0893 - mrcnn_bbox_loss: 3.2238 - mrcnn_mask_loss: 0.4296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 57) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - ETA: 0s - batch: 72.5000 - size: 2.0000 - loss: 12.5605 - rpn_class_loss: 2.1168 - rpn_bbox_loss: 6.8088 - mrcnn_class_loss: 0.0980 - mrcnn_bbox_loss: 3.1022 - mrcnn_mask_loss: 0.4347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (1024, 1024, 49) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
      "  ia.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 271s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 12.5605 - rpn_class_loss: 2.1168 - rpn_bbox_loss: 6.8088 - mrcnn_class_loss: 0.0980 - mrcnn_bbox_loss: 3.1022 - mrcnn_mask_loss: 0.4347 - val_loss: 6.6283 - val_rpn_class_loss: 1.6787 - val_rpn_bbox_loss: 3.0988 - val_mrcnn_class_loss: 0.1368 - val_mrcnn_bbox_loss: 1.2065 - val_mrcnn_mask_loss: 0.5075\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 227s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 3.2932 - rpn_class_loss: 0.4383 - rpn_bbox_loss: 1.1955 - mrcnn_class_loss: 0.3060 - mrcnn_bbox_loss: 0.8922 - mrcnn_mask_loss: 0.4612 - val_loss: 3.0203 - val_rpn_class_loss: 0.6283 - val_rpn_bbox_loss: 0.8976 - val_mrcnn_class_loss: 0.2936 - val_mrcnn_bbox_loss: 0.7569 - val_mrcnn_mask_loss: 0.4439\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 248s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 2.2268 - rpn_class_loss: 0.2899 - rpn_bbox_loss: 0.5614 - mrcnn_class_loss: 0.3434 - mrcnn_bbox_loss: 0.5912 - mrcnn_mask_loss: 0.4408 - val_loss: 2.7759 - val_rpn_class_loss: 0.6440 - val_rpn_bbox_loss: 0.7424 - val_mrcnn_class_loss: 0.3757 - val_mrcnn_bbox_loss: 0.5791 - val_mrcnn_mask_loss: 0.4347\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 223s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.9786 - rpn_class_loss: 0.2363 - rpn_bbox_loss: 0.4520 - mrcnn_class_loss: 0.3972 - mrcnn_bbox_loss: 0.4790 - mrcnn_mask_loss: 0.4141 - val_loss: 2.4127 - val_rpn_class_loss: 0.5797 - val_rpn_bbox_loss: 0.5948 - val_mrcnn_class_loss: 0.3318 - val_mrcnn_bbox_loss: 0.5186 - val_mrcnn_mask_loss: 0.3877\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 223s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.8290 - rpn_class_loss: 0.1964 - rpn_bbox_loss: 0.4164 - mrcnn_class_loss: 0.3842 - mrcnn_bbox_loss: 0.4305 - mrcnn_mask_loss: 0.4016 - val_loss: 2.3459 - val_rpn_class_loss: 0.5252 - val_rpn_bbox_loss: 0.6423 - val_mrcnn_class_loss: 0.3229 - val_mrcnn_bbox_loss: 0.4699 - val_mrcnn_mask_loss: 0.3857\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 228s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.7600 - rpn_class_loss: 0.1945 - rpn_bbox_loss: 0.3858 - mrcnn_class_loss: 0.4016 - mrcnn_bbox_loss: 0.3892 - mrcnn_mask_loss: 0.3888 - val_loss: 2.8778 - val_rpn_class_loss: 0.8262 - val_rpn_bbox_loss: 0.7822 - val_mrcnn_class_loss: 0.3722 - val_mrcnn_bbox_loss: 0.4764 - val_mrcnn_mask_loss: 0.4208\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 240s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.7377 - rpn_class_loss: 0.1996 - rpn_bbox_loss: 0.3934 - mrcnn_class_loss: 0.3832 - mrcnn_bbox_loss: 0.3721 - mrcnn_mask_loss: 0.3895 - val_loss: 2.2528 - val_rpn_class_loss: 0.5137 - val_rpn_bbox_loss: 0.5454 - val_mrcnn_class_loss: 0.3391 - val_mrcnn_bbox_loss: 0.4857 - val_mrcnn_mask_loss: 0.3689\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 247s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.6601 - rpn_class_loss: 0.1803 - rpn_bbox_loss: 0.3582 - mrcnn_class_loss: 0.3903 - mrcnn_bbox_loss: 0.3499 - mrcnn_mask_loss: 0.3815 - val_loss: 2.2649 - val_rpn_class_loss: 0.5534 - val_rpn_bbox_loss: 0.5206 - val_mrcnn_class_loss: 0.3585 - val_mrcnn_bbox_loss: 0.4709 - val_mrcnn_mask_loss: 0.3614\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 247s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.6126 - rpn_class_loss: 0.1721 - rpn_bbox_loss: 0.3629 - mrcnn_class_loss: 0.3585 - mrcnn_bbox_loss: 0.3388 - mrcnn_mask_loss: 0.3803 - val_loss: 2.1561 - val_rpn_class_loss: 0.5527 - val_rpn_bbox_loss: 0.5261 - val_mrcnn_class_loss: 0.3171 - val_mrcnn_bbox_loss: 0.4250 - val_mrcnn_mask_loss: 0.3352\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 231s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.5376 - rpn_class_loss: 0.1728 - rpn_bbox_loss: 0.3307 - mrcnn_class_loss: 0.3460 - mrcnn_bbox_loss: 0.3198 - mrcnn_mask_loss: 0.3684 - val_loss: 2.1567 - val_rpn_class_loss: 0.5087 - val_rpn_bbox_loss: 0.5215 - val_mrcnn_class_loss: 0.3672 - val_mrcnn_bbox_loss: 0.3969 - val_mrcnn_mask_loss: 0.3625\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 242s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.5245 - rpn_class_loss: 0.1699 - rpn_bbox_loss: 0.3516 - mrcnn_class_loss: 0.3353 - mrcnn_bbox_loss: 0.2996 - mrcnn_mask_loss: 0.3681 - val_loss: 2.3833 - val_rpn_class_loss: 0.5786 - val_rpn_bbox_loss: 0.6309 - val_mrcnn_class_loss: 0.3314 - val_mrcnn_bbox_loss: 0.4613 - val_mrcnn_mask_loss: 0.3811\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 226s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.4774 - rpn_class_loss: 0.1551 - rpn_bbox_loss: 0.3221 - mrcnn_class_loss: 0.3356 - mrcnn_bbox_loss: 0.3009 - mrcnn_mask_loss: 0.3636 - val_loss: 2.2241 - val_rpn_class_loss: 0.5535 - val_rpn_bbox_loss: 0.5698 - val_mrcnn_class_loss: 0.3327 - val_mrcnn_bbox_loss: 0.3949 - val_mrcnn_mask_loss: 0.3732\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 230s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.4315 - rpn_class_loss: 0.1463 - rpn_bbox_loss: 0.3179 - mrcnn_class_loss: 0.3215 - mrcnn_bbox_loss: 0.2842 - mrcnn_mask_loss: 0.3616 - val_loss: 2.3237 - val_rpn_class_loss: 0.5500 - val_rpn_bbox_loss: 0.6282 - val_mrcnn_class_loss: 0.3684 - val_mrcnn_bbox_loss: 0.3993 - val_mrcnn_mask_loss: 0.3778\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 224s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.4302 - rpn_class_loss: 0.1539 - rpn_bbox_loss: 0.3196 - mrcnn_class_loss: 0.3163 - mrcnn_bbox_loss: 0.2784 - mrcnn_mask_loss: 0.3620 - val_loss: 2.1919 - val_rpn_class_loss: 0.4699 - val_rpn_bbox_loss: 0.5711 - val_mrcnn_class_loss: 0.3518 - val_mrcnn_bbox_loss: 0.4588 - val_mrcnn_mask_loss: 0.3402\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 251s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.4200 - rpn_class_loss: 0.1562 - rpn_bbox_loss: 0.3324 - mrcnn_class_loss: 0.3082 - mrcnn_bbox_loss: 0.2670 - mrcnn_mask_loss: 0.3562 - val_loss: 2.2039 - val_rpn_class_loss: 0.4664 - val_rpn_bbox_loss: 0.5412 - val_mrcnn_class_loss: 0.4205 - val_mrcnn_bbox_loss: 0.3953 - val_mrcnn_mask_loss: 0.3805\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 237s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.3618 - rpn_class_loss: 0.1441 - rpn_bbox_loss: 0.3095 - mrcnn_class_loss: 0.2915 - mrcnn_bbox_loss: 0.2623 - mrcnn_mask_loss: 0.3545 - val_loss: 2.1971 - val_rpn_class_loss: 0.5427 - val_rpn_bbox_loss: 0.5633 - val_mrcnn_class_loss: 0.3423 - val_mrcnn_bbox_loss: 0.3837 - val_mrcnn_mask_loss: 0.3650\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 216s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.3264 - rpn_class_loss: 0.1384 - rpn_bbox_loss: 0.2939 - mrcnn_class_loss: 0.2934 - mrcnn_bbox_loss: 0.2515 - mrcnn_mask_loss: 0.3492 - val_loss: 2.2168 - val_rpn_class_loss: 0.5560 - val_rpn_bbox_loss: 0.5629 - val_mrcnn_class_loss: 0.3331 - val_mrcnn_bbox_loss: 0.3884 - val_mrcnn_mask_loss: 0.3765\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 228s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.3288 - rpn_class_loss: 0.1547 - rpn_bbox_loss: 0.3037 - mrcnn_class_loss: 0.2814 - mrcnn_bbox_loss: 0.2425 - mrcnn_mask_loss: 0.3464 - val_loss: 2.0910 - val_rpn_class_loss: 0.4184 - val_rpn_bbox_loss: 0.5239 - val_mrcnn_class_loss: 0.3970 - val_mrcnn_bbox_loss: 0.3852 - val_mrcnn_mask_loss: 0.3665\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 235s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2789 - rpn_class_loss: 0.1404 - rpn_bbox_loss: 0.2900 - mrcnn_class_loss: 0.2739 - mrcnn_bbox_loss: 0.2325 - mrcnn_mask_loss: 0.3420 - val_loss: 2.2599 - val_rpn_class_loss: 0.6082 - val_rpn_bbox_loss: 0.5355 - val_mrcnn_class_loss: 0.3602 - val_mrcnn_bbox_loss: 0.3953 - val_mrcnn_mask_loss: 0.3608\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 217s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2288 - rpn_class_loss: 0.1261 - rpn_bbox_loss: 0.2693 - mrcnn_class_loss: 0.2745 - mrcnn_bbox_loss: 0.2222 - mrcnn_mask_loss: 0.3367 - val_loss: 2.2793 - val_rpn_class_loss: 0.5091 - val_rpn_bbox_loss: 0.5937 - val_mrcnn_class_loss: 0.4009 - val_mrcnn_bbox_loss: 0.4021 - val_mrcnn_mask_loss: 0.3735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "146/146 [==============================] - 227s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2518 - rpn_class_loss: 0.1274 - rpn_bbox_loss: 0.2829 - mrcnn_class_loss: 0.2764 - mrcnn_bbox_loss: 0.2238 - mrcnn_mask_loss: 0.3413 - val_loss: 2.1347 - val_rpn_class_loss: 0.4622 - val_rpn_bbox_loss: 0.5574 - val_mrcnn_class_loss: 0.3199 - val_mrcnn_bbox_loss: 0.4519 - val_mrcnn_mask_loss: 0.3433\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 213s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2083 - rpn_class_loss: 0.1284 - rpn_bbox_loss: 0.2685 - mrcnn_class_loss: 0.2576 - mrcnn_bbox_loss: 0.2170 - mrcnn_mask_loss: 0.3369 - val_loss: 2.0753 - val_rpn_class_loss: 0.4567 - val_rpn_bbox_loss: 0.5228 - val_mrcnn_class_loss: 0.3397 - val_mrcnn_bbox_loss: 0.3838 - val_mrcnn_mask_loss: 0.3723\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 210s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2064 - rpn_class_loss: 0.1268 - rpn_bbox_loss: 0.2743 - mrcnn_class_loss: 0.2576 - mrcnn_bbox_loss: 0.2113 - mrcnn_mask_loss: 0.3363 - val_loss: 2.0961 - val_rpn_class_loss: 0.4936 - val_rpn_bbox_loss: 0.5258 - val_mrcnn_class_loss: 0.3412 - val_mrcnn_bbox_loss: 0.3937 - val_mrcnn_mask_loss: 0.3418\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 235s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1783 - rpn_class_loss: 0.1216 - rpn_bbox_loss: 0.2592 - mrcnn_class_loss: 0.2542 - mrcnn_bbox_loss: 0.2107 - mrcnn_mask_loss: 0.3326 - val_loss: 2.0727 - val_rpn_class_loss: 0.4493 - val_rpn_bbox_loss: 0.5591 - val_mrcnn_class_loss: 0.3685 - val_mrcnn_bbox_loss: 0.3556 - val_mrcnn_mask_loss: 0.3402\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 221s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1698 - rpn_class_loss: 0.1141 - rpn_bbox_loss: 0.2462 - mrcnn_class_loss: 0.2623 - mrcnn_bbox_loss: 0.2127 - mrcnn_mask_loss: 0.3345 - val_loss: 2.0843 - val_rpn_class_loss: 0.4440 - val_rpn_bbox_loss: 0.5408 - val_mrcnn_class_loss: 0.3534 - val_mrcnn_bbox_loss: 0.3642 - val_mrcnn_mask_loss: 0.3819\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 245s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1581 - rpn_class_loss: 0.1259 - rpn_bbox_loss: 0.2453 - mrcnn_class_loss: 0.2504 - mrcnn_bbox_loss: 0.2036 - mrcnn_mask_loss: 0.3329 - val_loss: 1.9980 - val_rpn_class_loss: 0.4440 - val_rpn_bbox_loss: 0.5309 - val_mrcnn_class_loss: 0.3297 - val_mrcnn_bbox_loss: 0.3588 - val_mrcnn_mask_loss: 0.3347\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 230s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1381 - rpn_class_loss: 0.1189 - rpn_bbox_loss: 0.2527 - mrcnn_class_loss: 0.2438 - mrcnn_bbox_loss: 0.1976 - mrcnn_mask_loss: 0.3251 - val_loss: 2.3364 - val_rpn_class_loss: 0.6353 - val_rpn_bbox_loss: 0.6235 - val_mrcnn_class_loss: 0.3486 - val_mrcnn_bbox_loss: 0.3698 - val_mrcnn_mask_loss: 0.3592\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 223s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1102 - rpn_class_loss: 0.1159 - rpn_bbox_loss: 0.2426 - mrcnn_class_loss: 0.2354 - mrcnn_bbox_loss: 0.1933 - mrcnn_mask_loss: 0.3230 - val_loss: 2.1138 - val_rpn_class_loss: 0.4551 - val_rpn_bbox_loss: 0.5527 - val_mrcnn_class_loss: 0.3941 - val_mrcnn_bbox_loss: 0.3680 - val_mrcnn_mask_loss: 0.3439\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 242s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0951 - rpn_class_loss: 0.1058 - rpn_bbox_loss: 0.2379 - mrcnn_class_loss: 0.2309 - mrcnn_bbox_loss: 0.1944 - mrcnn_mask_loss: 0.3262 - val_loss: 2.2631 - val_rpn_class_loss: 0.5687 - val_rpn_bbox_loss: 0.5511 - val_mrcnn_class_loss: 0.4227 - val_mrcnn_bbox_loss: 0.3758 - val_mrcnn_mask_loss: 0.3448\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 215s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0660 - rpn_class_loss: 0.1050 - rpn_bbox_loss: 0.2257 - mrcnn_class_loss: 0.2282 - mrcnn_bbox_loss: 0.1841 - mrcnn_mask_loss: 0.3228 - val_loss: 2.2452 - val_rpn_class_loss: 0.5433 - val_rpn_bbox_loss: 0.5665 - val_mrcnn_class_loss: 0.3774 - val_mrcnn_bbox_loss: 0.3985 - val_mrcnn_mask_loss: 0.3594\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 232s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0575 - rpn_class_loss: 0.1095 - rpn_bbox_loss: 0.2268 - mrcnn_class_loss: 0.2181 - mrcnn_bbox_loss: 0.1824 - mrcnn_mask_loss: 0.3207 - val_loss: 2.4207 - val_rpn_class_loss: 0.7202 - val_rpn_bbox_loss: 0.5687 - val_mrcnn_class_loss: 0.4047 - val_mrcnn_bbox_loss: 0.3854 - val_mrcnn_mask_loss: 0.3415\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 231s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0859 - rpn_class_loss: 0.1099 - rpn_bbox_loss: 0.2353 - mrcnn_class_loss: 0.2286 - mrcnn_bbox_loss: 0.1872 - mrcnn_mask_loss: 0.3248 - val_loss: 2.1825 - val_rpn_class_loss: 0.5154 - val_rpn_bbox_loss: 0.5580 - val_mrcnn_class_loss: 0.3772 - val_mrcnn_bbox_loss: 0.3825 - val_mrcnn_mask_loss: 0.3494\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0605 - rpn_class_loss: 0.1067 - rpn_bbox_loss: 0.2292 - mrcnn_class_loss: 0.2190 - mrcnn_bbox_loss: 0.1855 - mrcnn_mask_loss: 0.3201 - val_loss: 2.1943 - val_rpn_class_loss: 0.5680 - val_rpn_bbox_loss: 0.5392 - val_mrcnn_class_loss: 0.3833 - val_mrcnn_bbox_loss: 0.3491 - val_mrcnn_mask_loss: 0.3546\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 197s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0220 - rpn_class_loss: 0.0960 - rpn_bbox_loss: 0.2139 - mrcnn_class_loss: 0.2176 - mrcnn_bbox_loss: 0.1755 - mrcnn_mask_loss: 0.3189 - val_loss: 2.0332 - val_rpn_class_loss: 0.4509 - val_rpn_bbox_loss: 0.5147 - val_mrcnn_class_loss: 0.3677 - val_mrcnn_bbox_loss: 0.3654 - val_mrcnn_mask_loss: 0.3346\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 237s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0103 - rpn_class_loss: 0.1018 - rpn_bbox_loss: 0.2209 - mrcnn_class_loss: 0.2024 - mrcnn_bbox_loss: 0.1700 - mrcnn_mask_loss: 0.3153 - val_loss: 2.1382 - val_rpn_class_loss: 0.4750 - val_rpn_bbox_loss: 0.5474 - val_mrcnn_class_loss: 0.3948 - val_mrcnn_bbox_loss: 0.3630 - val_mrcnn_mask_loss: 0.3580\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0044 - rpn_class_loss: 0.1027 - rpn_bbox_loss: 0.2177 - mrcnn_class_loss: 0.2013 - mrcnn_bbox_loss: 0.1674 - mrcnn_mask_loss: 0.3154 - val_loss: 2.2318 - val_rpn_class_loss: 0.4864 - val_rpn_bbox_loss: 0.5752 - val_mrcnn_class_loss: 0.4391 - val_mrcnn_bbox_loss: 0.3924 - val_mrcnn_mask_loss: 0.3387\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 220s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9909 - rpn_class_loss: 0.0960 - rpn_bbox_loss: 0.2188 - mrcnn_class_loss: 0.1968 - mrcnn_bbox_loss: 0.1665 - mrcnn_mask_loss: 0.3129 - val_loss: 2.0264 - val_rpn_class_loss: 0.3861 - val_rpn_bbox_loss: 0.4904 - val_mrcnn_class_loss: 0.4381 - val_mrcnn_bbox_loss: 0.3607 - val_mrcnn_mask_loss: 0.3511\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 232s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9740 - rpn_class_loss: 0.0918 - rpn_bbox_loss: 0.2014 - mrcnn_class_loss: 0.2005 - mrcnn_bbox_loss: 0.1669 - mrcnn_mask_loss: 0.3134 - val_loss: 2.2133 - val_rpn_class_loss: 0.4904 - val_rpn_bbox_loss: 0.5451 - val_mrcnn_class_loss: 0.4538 - val_mrcnn_bbox_loss: 0.3639 - val_mrcnn_mask_loss: 0.3602\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 205s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0136 - rpn_class_loss: 0.1015 - rpn_bbox_loss: 0.2200 - mrcnn_class_loss: 0.2028 - mrcnn_bbox_loss: 0.1708 - mrcnn_mask_loss: 0.3185 - val_loss: 2.1728 - val_rpn_class_loss: 0.4249 - val_rpn_bbox_loss: 0.5600 - val_mrcnn_class_loss: 0.4296 - val_mrcnn_bbox_loss: 0.3679 - val_mrcnn_mask_loss: 0.3904\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 234s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9790 - rpn_class_loss: 0.0909 - rpn_bbox_loss: 0.2111 - mrcnn_class_loss: 0.1980 - mrcnn_bbox_loss: 0.1646 - mrcnn_mask_loss: 0.3143 - val_loss: 2.0927 - val_rpn_class_loss: 0.5297 - val_rpn_bbox_loss: 0.5332 - val_mrcnn_class_loss: 0.3489 - val_mrcnn_bbox_loss: 0.3551 - val_mrcnn_mask_loss: 0.3257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "146/146 [==============================] - 239s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9466 - rpn_class_loss: 0.0893 - rpn_bbox_loss: 0.1990 - mrcnn_class_loss: 0.1915 - mrcnn_bbox_loss: 0.1577 - mrcnn_mask_loss: 0.3090 - val_loss: 2.2438 - val_rpn_class_loss: 0.4906 - val_rpn_bbox_loss: 0.5553 - val_mrcnn_class_loss: 0.4798 - val_mrcnn_bbox_loss: 0.3575 - val_mrcnn_mask_loss: 0.3606\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 230s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9311 - rpn_class_loss: 0.0832 - rpn_bbox_loss: 0.1948 - mrcnn_class_loss: 0.1918 - mrcnn_bbox_loss: 0.1566 - mrcnn_mask_loss: 0.3047 - val_loss: 2.3996 - val_rpn_class_loss: 0.6328 - val_rpn_bbox_loss: 0.5360 - val_mrcnn_class_loss: 0.5241 - val_mrcnn_bbox_loss: 0.3571 - val_mrcnn_mask_loss: 0.3495\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 237s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9536 - rpn_class_loss: 0.0930 - rpn_bbox_loss: 0.2037 - mrcnn_class_loss: 0.1892 - mrcnn_bbox_loss: 0.1607 - mrcnn_mask_loss: 0.3071 - val_loss: 2.1403 - val_rpn_class_loss: 0.5411 - val_rpn_bbox_loss: 0.5042 - val_mrcnn_class_loss: 0.3990 - val_mrcnn_bbox_loss: 0.3446 - val_mrcnn_mask_loss: 0.3515\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 227s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9185 - rpn_class_loss: 0.0857 - rpn_bbox_loss: 0.1931 - mrcnn_class_loss: 0.1836 - mrcnn_bbox_loss: 0.1527 - mrcnn_mask_loss: 0.3034 - val_loss: 2.3416 - val_rpn_class_loss: 0.6462 - val_rpn_bbox_loss: 0.5412 - val_mrcnn_class_loss: 0.4546 - val_mrcnn_bbox_loss: 0.3504 - val_mrcnn_mask_loss: 0.3493\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 237s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9147 - rpn_class_loss: 0.0895 - rpn_bbox_loss: 0.1918 - mrcnn_class_loss: 0.1783 - mrcnn_bbox_loss: 0.1491 - mrcnn_mask_loss: 0.3062 - val_loss: 2.1721 - val_rpn_class_loss: 0.4830 - val_rpn_bbox_loss: 0.5606 - val_mrcnn_class_loss: 0.4242 - val_mrcnn_bbox_loss: 0.3448 - val_mrcnn_mask_loss: 0.3596\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 239s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9242 - rpn_class_loss: 0.0873 - rpn_bbox_loss: 0.1944 - mrcnn_class_loss: 0.1831 - mrcnn_bbox_loss: 0.1524 - mrcnn_mask_loss: 0.3070 - val_loss: 2.3820 - val_rpn_class_loss: 0.6338 - val_rpn_bbox_loss: 0.5519 - val_mrcnn_class_loss: 0.4915 - val_mrcnn_bbox_loss: 0.3671 - val_mrcnn_mask_loss: 0.3377\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 225s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9009 - rpn_class_loss: 0.0902 - rpn_bbox_loss: 0.1882 - mrcnn_class_loss: 0.1714 - mrcnn_bbox_loss: 0.1460 - mrcnn_mask_loss: 0.3051 - val_loss: 2.1903 - val_rpn_class_loss: 0.4818 - val_rpn_bbox_loss: 0.5059 - val_mrcnn_class_loss: 0.5100 - val_mrcnn_bbox_loss: 0.3562 - val_mrcnn_mask_loss: 0.3363\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 255s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8817 - rpn_class_loss: 0.0829 - rpn_bbox_loss: 0.1848 - mrcnn_class_loss: 0.1733 - mrcnn_bbox_loss: 0.1416 - mrcnn_mask_loss: 0.2991 - val_loss: 2.1951 - val_rpn_class_loss: 0.5347 - val_rpn_bbox_loss: 0.5587 - val_mrcnn_class_loss: 0.3889 - val_mrcnn_bbox_loss: 0.3578 - val_mrcnn_mask_loss: 0.3550\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 232s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8681 - rpn_class_loss: 0.0783 - rpn_bbox_loss: 0.1791 - mrcnn_class_loss: 0.1699 - mrcnn_bbox_loss: 0.1433 - mrcnn_mask_loss: 0.2975 - val_loss: 2.2782 - val_rpn_class_loss: 0.6027 - val_rpn_bbox_loss: 0.5290 - val_mrcnn_class_loss: 0.4386 - val_mrcnn_bbox_loss: 0.3435 - val_mrcnn_mask_loss: 0.3645\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 246s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8832 - rpn_class_loss: 0.0809 - rpn_bbox_loss: 0.1856 - mrcnn_class_loss: 0.1697 - mrcnn_bbox_loss: 0.1435 - mrcnn_mask_loss: 0.3035 - val_loss: 2.2467 - val_rpn_class_loss: 0.5336 - val_rpn_bbox_loss: 0.5750 - val_mrcnn_class_loss: 0.4350 - val_mrcnn_bbox_loss: 0.3485 - val_mrcnn_mask_loss: 0.3545\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 209s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8338 - rpn_class_loss: 0.0744 - rpn_bbox_loss: 0.1693 - mrcnn_class_loss: 0.1553 - mrcnn_bbox_loss: 0.1392 - mrcnn_mask_loss: 0.2957 - val_loss: 2.1899 - val_rpn_class_loss: 0.5216 - val_rpn_bbox_loss: 0.4926 - val_mrcnn_class_loss: 0.4758 - val_mrcnn_bbox_loss: 0.3604 - val_mrcnn_mask_loss: 0.3396\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 255s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8629 - rpn_class_loss: 0.0808 - rpn_bbox_loss: 0.1816 - mrcnn_class_loss: 0.1652 - mrcnn_bbox_loss: 0.1385 - mrcnn_mask_loss: 0.2968 - val_loss: 2.3009 - val_rpn_class_loss: 0.5735 - val_rpn_bbox_loss: 0.5117 - val_mrcnn_class_loss: 0.4991 - val_mrcnn_bbox_loss: 0.3517 - val_mrcnn_mask_loss: 0.3649\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 228s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8411 - rpn_class_loss: 0.0791 - rpn_bbox_loss: 0.1745 - mrcnn_class_loss: 0.1553 - mrcnn_bbox_loss: 0.1341 - mrcnn_mask_loss: 0.2981 - val_loss: 2.2755 - val_rpn_class_loss: 0.6094 - val_rpn_bbox_loss: 0.5352 - val_mrcnn_class_loss: 0.4418 - val_mrcnn_bbox_loss: 0.3487 - val_mrcnn_mask_loss: 0.3403\n",
      "Epoch 54/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8182 - rpn_class_loss: 0.0739 - rpn_bbox_loss: 0.1654 - mrcnn_class_loss: 0.1518 - mrcnn_bbox_loss: 0.1336 - mrcnn_mask_loss: 0.2934 - val_loss: 2.3236 - val_rpn_class_loss: 0.5632 - val_rpn_bbox_loss: 0.5447 - val_mrcnn_class_loss: 0.5100 - val_mrcnn_bbox_loss: 0.3552 - val_mrcnn_mask_loss: 0.3506\n",
      "Epoch 55/100\n",
      "146/146 [==============================] - 239s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8357 - rpn_class_loss: 0.0781 - rpn_bbox_loss: 0.1759 - mrcnn_class_loss: 0.1519 - mrcnn_bbox_loss: 0.1360 - mrcnn_mask_loss: 0.2937 - val_loss: 2.0262 - val_rpn_class_loss: 0.4611 - val_rpn_bbox_loss: 0.4898 - val_mrcnn_class_loss: 0.3915 - val_mrcnn_bbox_loss: 0.3344 - val_mrcnn_mask_loss: 0.3494\n",
      "Epoch 56/100\n",
      "146/146 [==============================] - 226s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8073 - rpn_class_loss: 0.0766 - rpn_bbox_loss: 0.1650 - mrcnn_class_loss: 0.1463 - mrcnn_bbox_loss: 0.1289 - mrcnn_mask_loss: 0.2906 - val_loss: 2.2079 - val_rpn_class_loss: 0.5055 - val_rpn_bbox_loss: 0.5401 - val_mrcnn_class_loss: 0.4876 - val_mrcnn_bbox_loss: 0.3400 - val_mrcnn_mask_loss: 0.3347\n",
      "Epoch 57/100\n",
      "146/146 [==============================] - 240s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7829 - rpn_class_loss: 0.0677 - rpn_bbox_loss: 0.1557 - mrcnn_class_loss: 0.1441 - mrcnn_bbox_loss: 0.1250 - mrcnn_mask_loss: 0.2904 - val_loss: 2.1777 - val_rpn_class_loss: 0.5140 - val_rpn_bbox_loss: 0.5140 - val_mrcnn_class_loss: 0.4569 - val_mrcnn_bbox_loss: 0.3529 - val_mrcnn_mask_loss: 0.3399\n",
      "Epoch 58/100\n",
      "146/146 [==============================] - 223s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7832 - rpn_class_loss: 0.0731 - rpn_bbox_loss: 0.1606 - mrcnn_class_loss: 0.1399 - mrcnn_bbox_loss: 0.1230 - mrcnn_mask_loss: 0.2866 - val_loss: 2.2547 - val_rpn_class_loss: 0.5452 - val_rpn_bbox_loss: 0.5325 - val_mrcnn_class_loss: 0.4745 - val_mrcnn_bbox_loss: 0.3437 - val_mrcnn_mask_loss: 0.3589\n",
      "Epoch 59/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7919 - rpn_class_loss: 0.0761 - rpn_bbox_loss: 0.1635 - mrcnn_class_loss: 0.1379 - mrcnn_bbox_loss: 0.1241 - mrcnn_mask_loss: 0.2903 - val_loss: 2.2115 - val_rpn_class_loss: 0.5254 - val_rpn_bbox_loss: 0.5185 - val_mrcnn_class_loss: 0.4563 - val_mrcnn_bbox_loss: 0.3577 - val_mrcnn_mask_loss: 0.3536\n",
      "Epoch 60/100\n",
      "146/146 [==============================] - 225s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7979 - rpn_class_loss: 0.0738 - rpn_bbox_loss: 0.1660 - mrcnn_class_loss: 0.1424 - mrcnn_bbox_loss: 0.1239 - mrcnn_mask_loss: 0.2918 - val_loss: 2.5116 - val_rpn_class_loss: 0.7173 - val_rpn_bbox_loss: 0.5724 - val_mrcnn_class_loss: 0.5295 - val_mrcnn_bbox_loss: 0.3714 - val_mrcnn_mask_loss: 0.3209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "146/146 [==============================] - 229s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7718 - rpn_class_loss: 0.0725 - rpn_bbox_loss: 0.1539 - mrcnn_class_loss: 0.1372 - mrcnn_bbox_loss: 0.1214 - mrcnn_mask_loss: 0.2869 - val_loss: 2.4779 - val_rpn_class_loss: 0.6169 - val_rpn_bbox_loss: 0.5394 - val_mrcnn_class_loss: 0.6046 - val_mrcnn_bbox_loss: 0.3675 - val_mrcnn_mask_loss: 0.3494\n",
      "Epoch 62/100\n",
      "146/146 [==============================] - 239s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7888 - rpn_class_loss: 0.0753 - rpn_bbox_loss: 0.1688 - mrcnn_class_loss: 0.1343 - mrcnn_bbox_loss: 0.1220 - mrcnn_mask_loss: 0.2885 - val_loss: 2.2898 - val_rpn_class_loss: 0.5363 - val_rpn_bbox_loss: 0.5709 - val_mrcnn_class_loss: 0.4664 - val_mrcnn_bbox_loss: 0.3610 - val_mrcnn_mask_loss: 0.3552\n",
      "Epoch 63/100\n",
      "146/146 [==============================] - 218s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7276 - rpn_class_loss: 0.0635 - rpn_bbox_loss: 0.1384 - mrcnn_class_loss: 0.1298 - mrcnn_bbox_loss: 0.1145 - mrcnn_mask_loss: 0.2815 - val_loss: 2.3283 - val_rpn_class_loss: 0.6002 - val_rpn_bbox_loss: 0.5231 - val_mrcnn_class_loss: 0.5268 - val_mrcnn_bbox_loss: 0.3348 - val_mrcnn_mask_loss: 0.3434\n",
      "Epoch 64/100\n",
      "146/146 [==============================] - 247s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7447 - rpn_class_loss: 0.0658 - rpn_bbox_loss: 0.1498 - mrcnn_class_loss: 0.1301 - mrcnn_bbox_loss: 0.1160 - mrcnn_mask_loss: 0.2830 - val_loss: 2.2595 - val_rpn_class_loss: 0.5571 - val_rpn_bbox_loss: 0.5197 - val_mrcnn_class_loss: 0.5087 - val_mrcnn_bbox_loss: 0.3337 - val_mrcnn_mask_loss: 0.3403\n",
      "Epoch 65/100\n",
      "146/146 [==============================] - 254s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7575 - rpn_class_loss: 0.0692 - rpn_bbox_loss: 0.1494 - mrcnn_class_loss: 0.1339 - mrcnn_bbox_loss: 0.1205 - mrcnn_mask_loss: 0.2845 - val_loss: 2.3986 - val_rpn_class_loss: 0.5888 - val_rpn_bbox_loss: 0.6149 - val_mrcnn_class_loss: 0.4995 - val_mrcnn_bbox_loss: 0.3672 - val_mrcnn_mask_loss: 0.3281\n",
      "Epoch 66/100\n",
      "146/146 [==============================] - 238s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7468 - rpn_class_loss: 0.0639 - rpn_bbox_loss: 0.1504 - mrcnn_class_loss: 0.1315 - mrcnn_bbox_loss: 0.1177 - mrcnn_mask_loss: 0.2833 - val_loss: 2.4287 - val_rpn_class_loss: 0.6211 - val_rpn_bbox_loss: 0.5597 - val_mrcnn_class_loss: 0.5520 - val_mrcnn_bbox_loss: 0.3540 - val_mrcnn_mask_loss: 0.3418\n",
      "Epoch 67/100\n",
      "146/146 [==============================] - 210s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7059 - rpn_class_loss: 0.0606 - rpn_bbox_loss: 0.1326 - mrcnn_class_loss: 0.1229 - mrcnn_bbox_loss: 0.1111 - mrcnn_mask_loss: 0.2788 - val_loss: 2.2862 - val_rpn_class_loss: 0.5509 - val_rpn_bbox_loss: 0.5353 - val_mrcnn_class_loss: 0.5061 - val_mrcnn_bbox_loss: 0.3452 - val_mrcnn_mask_loss: 0.3486\n",
      "Epoch 68/100\n",
      "146/146 [==============================] - 218s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7128 - rpn_class_loss: 0.0597 - rpn_bbox_loss: 0.1363 - mrcnn_class_loss: 0.1262 - mrcnn_bbox_loss: 0.1126 - mrcnn_mask_loss: 0.2780 - val_loss: 2.3277 - val_rpn_class_loss: 0.6152 - val_rpn_bbox_loss: 0.5162 - val_mrcnn_class_loss: 0.5431 - val_mrcnn_bbox_loss: 0.3415 - val_mrcnn_mask_loss: 0.3117\n",
      "Epoch 69/100\n",
      "146/146 [==============================] - 233s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7216 - rpn_class_loss: 0.0674 - rpn_bbox_loss: 0.1428 - mrcnn_class_loss: 0.1202 - mrcnn_bbox_loss: 0.1103 - mrcnn_mask_loss: 0.2809 - val_loss: 2.4509 - val_rpn_class_loss: 0.7020 - val_rpn_bbox_loss: 0.5424 - val_mrcnn_class_loss: 0.5216 - val_mrcnn_bbox_loss: 0.3521 - val_mrcnn_mask_loss: 0.3328\n",
      "Epoch 70/100\n",
      "146/146 [==============================] - 218s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7027 - rpn_class_loss: 0.0615 - rpn_bbox_loss: 0.1392 - mrcnn_class_loss: 0.1192 - mrcnn_bbox_loss: 0.1075 - mrcnn_mask_loss: 0.2753 - val_loss: 2.4196 - val_rpn_class_loss: 0.6601 - val_rpn_bbox_loss: 0.5536 - val_mrcnn_class_loss: 0.5126 - val_mrcnn_bbox_loss: 0.3568 - val_mrcnn_mask_loss: 0.3365\n",
      "Epoch 71/100\n",
      "146/146 [==============================] - 239s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7032 - rpn_class_loss: 0.0625 - rpn_bbox_loss: 0.1349 - mrcnn_class_loss: 0.1189 - mrcnn_bbox_loss: 0.1072 - mrcnn_mask_loss: 0.2797 - val_loss: 2.2571 - val_rpn_class_loss: 0.5295 - val_rpn_bbox_loss: 0.5330 - val_mrcnn_class_loss: 0.5114 - val_mrcnn_bbox_loss: 0.3390 - val_mrcnn_mask_loss: 0.3442\n",
      "Epoch 72/100\n",
      "146/146 [==============================] - 195s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6761 - rpn_class_loss: 0.0583 - rpn_bbox_loss: 0.1277 - mrcnn_class_loss: 0.1148 - mrcnn_bbox_loss: 0.1036 - mrcnn_mask_loss: 0.2716 - val_loss: 2.1785 - val_rpn_class_loss: 0.4812 - val_rpn_bbox_loss: 0.4982 - val_mrcnn_class_loss: 0.4991 - val_mrcnn_bbox_loss: 0.3450 - val_mrcnn_mask_loss: 0.3549\n",
      "Epoch 73/100\n",
      "146/146 [==============================] - 215s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6981 - rpn_class_loss: 0.0596 - rpn_bbox_loss: 0.1373 - mrcnn_class_loss: 0.1166 - mrcnn_bbox_loss: 0.1075 - mrcnn_mask_loss: 0.2770 - val_loss: 2.4834 - val_rpn_class_loss: 0.6527 - val_rpn_bbox_loss: 0.5491 - val_mrcnn_class_loss: 0.6011 - val_mrcnn_bbox_loss: 0.3376 - val_mrcnn_mask_loss: 0.3429\n",
      "Epoch 74/100\n",
      "146/146 [==============================] - 253s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6816 - rpn_class_loss: 0.0593 - rpn_bbox_loss: 0.1259 - mrcnn_class_loss: 0.1129 - mrcnn_bbox_loss: 0.1048 - mrcnn_mask_loss: 0.2787 - val_loss: 2.5817 - val_rpn_class_loss: 0.7074 - val_rpn_bbox_loss: 0.5731 - val_mrcnn_class_loss: 0.6067 - val_mrcnn_bbox_loss: 0.3479 - val_mrcnn_mask_loss: 0.3466\n",
      "Epoch 75/100\n",
      "146/146 [==============================] - 250s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6824 - rpn_class_loss: 0.0615 - rpn_bbox_loss: 0.1293 - mrcnn_class_loss: 0.1141 - mrcnn_bbox_loss: 0.1027 - mrcnn_mask_loss: 0.2749 - val_loss: 2.5489 - val_rpn_class_loss: 0.6197 - val_rpn_bbox_loss: 0.5539 - val_mrcnn_class_loss: 0.6468 - val_mrcnn_bbox_loss: 0.3521 - val_mrcnn_mask_loss: 0.3765\n",
      "Epoch 76/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6805 - rpn_class_loss: 0.0580 - rpn_bbox_loss: 0.1283 - mrcnn_class_loss: 0.1152 - mrcnn_bbox_loss: 0.1037 - mrcnn_mask_loss: 0.2752 - val_loss: 2.8216 - val_rpn_class_loss: 0.8333 - val_rpn_bbox_loss: 0.5914 - val_mrcnn_class_loss: 0.6701 - val_mrcnn_bbox_loss: 0.3556 - val_mrcnn_mask_loss: 0.3712\n",
      "Epoch 77/100\n",
      "146/146 [==============================] - 215s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6662 - rpn_class_loss: 0.0553 - rpn_bbox_loss: 0.1255 - mrcnn_class_loss: 0.1087 - mrcnn_bbox_loss: 0.1008 - mrcnn_mask_loss: 0.2759 - val_loss: 2.3574 - val_rpn_class_loss: 0.6233 - val_rpn_bbox_loss: 0.4870 - val_mrcnn_class_loss: 0.5959 - val_mrcnn_bbox_loss: 0.3257 - val_mrcnn_mask_loss: 0.3256\n",
      "Epoch 78/100\n",
      "146/146 [==============================] - 220s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6305 - rpn_class_loss: 0.0525 - rpn_bbox_loss: 0.1173 - mrcnn_class_loss: 0.0977 - mrcnn_bbox_loss: 0.0937 - mrcnn_mask_loss: 0.2693 - val_loss: 2.6225 - val_rpn_class_loss: 0.7301 - val_rpn_bbox_loss: 0.5247 - val_mrcnn_class_loss: 0.6819 - val_mrcnn_bbox_loss: 0.3446 - val_mrcnn_mask_loss: 0.3411\n",
      "Epoch 79/100\n",
      "146/146 [==============================] - 227s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6631 - rpn_class_loss: 0.0583 - rpn_bbox_loss: 0.1263 - mrcnn_class_loss: 0.1094 - mrcnn_bbox_loss: 0.0983 - mrcnn_mask_loss: 0.2708 - val_loss: 2.3781 - val_rpn_class_loss: 0.6330 - val_rpn_bbox_loss: 0.4853 - val_mrcnn_class_loss: 0.5962 - val_mrcnn_bbox_loss: 0.3359 - val_mrcnn_mask_loss: 0.3277\n",
      "Epoch 80/100\n",
      "146/146 [==============================] - 218s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6545 - rpn_class_loss: 0.0552 - rpn_bbox_loss: 0.1265 - mrcnn_class_loss: 0.1041 - mrcnn_bbox_loss: 0.0978 - mrcnn_mask_loss: 0.2709 - val_loss: 2.5486 - val_rpn_class_loss: 0.7993 - val_rpn_bbox_loss: 0.5487 - val_mrcnn_class_loss: 0.5017 - val_mrcnn_bbox_loss: 0.3636 - val_mrcnn_mask_loss: 0.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "146/146 [==============================] - 253s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6271 - rpn_class_loss: 0.0489 - rpn_bbox_loss: 0.1177 - mrcnn_class_loss: 0.0985 - mrcnn_bbox_loss: 0.0955 - mrcnn_mask_loss: 0.2665 - val_loss: 2.6169 - val_rpn_class_loss: 0.8295 - val_rpn_bbox_loss: 0.5569 - val_mrcnn_class_loss: 0.5483 - val_mrcnn_bbox_loss: 0.3502 - val_mrcnn_mask_loss: 0.3321\n",
      "Epoch 82/100\n",
      "146/146 [==============================] - 223s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6334 - rpn_class_loss: 0.0513 - rpn_bbox_loss: 0.1180 - mrcnn_class_loss: 0.0990 - mrcnn_bbox_loss: 0.0943 - mrcnn_mask_loss: 0.2708 - val_loss: 2.7102 - val_rpn_class_loss: 0.7791 - val_rpn_bbox_loss: 0.6010 - val_mrcnn_class_loss: 0.6344 - val_mrcnn_bbox_loss: 0.3505 - val_mrcnn_mask_loss: 0.3453\n",
      "Epoch 83/100\n",
      "146/146 [==============================] - 241s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6385 - rpn_class_loss: 0.0544 - rpn_bbox_loss: 0.1189 - mrcnn_class_loss: 0.0997 - mrcnn_bbox_loss: 0.0956 - mrcnn_mask_loss: 0.2699 - val_loss: 2.4458 - val_rpn_class_loss: 0.6373 - val_rpn_bbox_loss: 0.5219 - val_mrcnn_class_loss: 0.6088 - val_mrcnn_bbox_loss: 0.3434 - val_mrcnn_mask_loss: 0.3344\n",
      "Epoch 84/100\n",
      "146/146 [==============================] - 231s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6394 - rpn_class_loss: 0.0522 - rpn_bbox_loss: 0.1226 - mrcnn_class_loss: 0.1041 - mrcnn_bbox_loss: 0.0945 - mrcnn_mask_loss: 0.2660 - val_loss: 2.5456 - val_rpn_class_loss: 0.7382 - val_rpn_bbox_loss: 0.5372 - val_mrcnn_class_loss: 0.5920 - val_mrcnn_bbox_loss: 0.3389 - val_mrcnn_mask_loss: 0.3394\n",
      "Epoch 85/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6292 - rpn_class_loss: 0.0554 - rpn_bbox_loss: 0.1229 - mrcnn_class_loss: 0.0950 - mrcnn_bbox_loss: 0.0910 - mrcnn_mask_loss: 0.2650 - val_loss: 2.5384 - val_rpn_class_loss: 0.5852 - val_rpn_bbox_loss: 0.5652 - val_mrcnn_class_loss: 0.6379 - val_mrcnn_bbox_loss: 0.3859 - val_mrcnn_mask_loss: 0.3641\n",
      "Epoch 86/100\n",
      "146/146 [==============================] - 204s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6265 - rpn_class_loss: 0.0499 - rpn_bbox_loss: 0.1165 - mrcnn_class_loss: 0.0980 - mrcnn_bbox_loss: 0.0945 - mrcnn_mask_loss: 0.2676 - val_loss: 2.0999 - val_rpn_class_loss: 0.4502 - val_rpn_bbox_loss: 0.4351 - val_mrcnn_class_loss: 0.5499 - val_mrcnn_bbox_loss: 0.3347 - val_mrcnn_mask_loss: 0.3300\n",
      "Epoch 87/100\n",
      "146/146 [==============================] - 236s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6127 - rpn_class_loss: 0.0488 - rpn_bbox_loss: 0.1111 - mrcnn_class_loss: 0.0967 - mrcnn_bbox_loss: 0.0905 - mrcnn_mask_loss: 0.2655 - val_loss: 2.6902 - val_rpn_class_loss: 0.8538 - val_rpn_bbox_loss: 0.5489 - val_mrcnn_class_loss: 0.6055 - val_mrcnn_bbox_loss: 0.3515 - val_mrcnn_mask_loss: 0.3306\n",
      "Epoch 88/100\n",
      "146/146 [==============================] - 235s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6011 - rpn_class_loss: 0.0488 - rpn_bbox_loss: 0.1127 - mrcnn_class_loss: 0.0921 - mrcnn_bbox_loss: 0.0870 - mrcnn_mask_loss: 0.2605 - val_loss: 2.7451 - val_rpn_class_loss: 0.7465 - val_rpn_bbox_loss: 0.5817 - val_mrcnn_class_loss: 0.6938 - val_mrcnn_bbox_loss: 0.3689 - val_mrcnn_mask_loss: 0.3541\n",
      "Epoch 89/100\n",
      "146/146 [==============================] - 237s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6175 - rpn_class_loss: 0.0503 - rpn_bbox_loss: 0.1146 - mrcnn_class_loss: 0.0956 - mrcnn_bbox_loss: 0.0921 - mrcnn_mask_loss: 0.2649 - val_loss: 2.7169 - val_rpn_class_loss: 0.8187 - val_rpn_bbox_loss: 0.5518 - val_mrcnn_class_loss: 0.6387 - val_mrcnn_bbox_loss: 0.3603 - val_mrcnn_mask_loss: 0.3475\n",
      "Epoch 90/100\n",
      "146/146 [==============================] - 230s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6303 - rpn_class_loss: 0.0514 - rpn_bbox_loss: 0.1181 - mrcnn_class_loss: 0.0969 - mrcnn_bbox_loss: 0.0924 - mrcnn_mask_loss: 0.2714 - val_loss: 2.6561 - val_rpn_class_loss: 0.7959 - val_rpn_bbox_loss: 0.5323 - val_mrcnn_class_loss: 0.6276 - val_mrcnn_bbox_loss: 0.3627 - val_mrcnn_mask_loss: 0.3375\n",
      "Epoch 91/100\n",
      "146/146 [==============================] - 219s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5914 - rpn_class_loss: 0.0502 - rpn_bbox_loss: 0.1049 - mrcnn_class_loss: 0.0902 - mrcnn_bbox_loss: 0.0859 - mrcnn_mask_loss: 0.2603 - val_loss: 2.6900 - val_rpn_class_loss: 0.7325 - val_rpn_bbox_loss: 0.5666 - val_mrcnn_class_loss: 0.6851 - val_mrcnn_bbox_loss: 0.3555 - val_mrcnn_mask_loss: 0.3503\n",
      "Epoch 92/100\n",
      "146/146 [==============================] - 241s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6278 - rpn_class_loss: 0.0504 - rpn_bbox_loss: 0.1244 - mrcnn_class_loss: 0.0959 - mrcnn_bbox_loss: 0.0918 - mrcnn_mask_loss: 0.2652 - val_loss: 2.6822 - val_rpn_class_loss: 0.7426 - val_rpn_bbox_loss: 0.6153 - val_mrcnn_class_loss: 0.6148 - val_mrcnn_bbox_loss: 0.3702 - val_mrcnn_mask_loss: 0.3393\n",
      "Epoch 93/100\n",
      "146/146 [==============================] - 244s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5938 - rpn_class_loss: 0.0483 - rpn_bbox_loss: 0.1115 - mrcnn_class_loss: 0.0881 - mrcnn_bbox_loss: 0.0854 - mrcnn_mask_loss: 0.2605 - val_loss: 2.8384 - val_rpn_class_loss: 0.7689 - val_rpn_bbox_loss: 0.6658 - val_mrcnn_class_loss: 0.6972 - val_mrcnn_bbox_loss: 0.3612 - val_mrcnn_mask_loss: 0.3453\n",
      "Epoch 94/100\n",
      "146/146 [==============================] - 234s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5809 - rpn_class_loss: 0.0475 - rpn_bbox_loss: 0.1040 - mrcnn_class_loss: 0.0889 - mrcnn_bbox_loss: 0.0837 - mrcnn_mask_loss: 0.2568 - val_loss: 3.0084 - val_rpn_class_loss: 0.9565 - val_rpn_bbox_loss: 0.5412 - val_mrcnn_class_loss: 0.8216 - val_mrcnn_bbox_loss: 0.3504 - val_mrcnn_mask_loss: 0.3387\n",
      "Epoch 95/100\n",
      "146/146 [==============================] - 257s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5981 - rpn_class_loss: 0.0487 - rpn_bbox_loss: 0.1124 - mrcnn_class_loss: 0.0911 - mrcnn_bbox_loss: 0.0858 - mrcnn_mask_loss: 0.2601 - val_loss: 2.8544 - val_rpn_class_loss: 0.8415 - val_rpn_bbox_loss: 0.5634 - val_mrcnn_class_loss: 0.7466 - val_mrcnn_bbox_loss: 0.3601 - val_mrcnn_mask_loss: 0.3428\n",
      "Epoch 96/100\n",
      "146/146 [==============================] - 226s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5737 - rpn_class_loss: 0.0444 - rpn_bbox_loss: 0.1009 - mrcnn_class_loss: 0.0895 - mrcnn_bbox_loss: 0.0839 - mrcnn_mask_loss: 0.2551 - val_loss: 2.7334 - val_rpn_class_loss: 0.8281 - val_rpn_bbox_loss: 0.5459 - val_mrcnn_class_loss: 0.6541 - val_mrcnn_bbox_loss: 0.3416 - val_mrcnn_mask_loss: 0.3637\n",
      "Epoch 97/100\n",
      "146/146 [==============================] - 236s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5841 - rpn_class_loss: 0.0482 - rpn_bbox_loss: 0.1040 - mrcnn_class_loss: 0.0857 - mrcnn_bbox_loss: 0.0838 - mrcnn_mask_loss: 0.2623 - val_loss: 2.7651 - val_rpn_class_loss: 0.8844 - val_rpn_bbox_loss: 0.5636 - val_mrcnn_class_loss: 0.6287 - val_mrcnn_bbox_loss: 0.3484 - val_mrcnn_mask_loss: 0.3400\n",
      "Epoch 98/100\n",
      "146/146 [==============================] - 215s 1s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5710 - rpn_class_loss: 0.0427 - rpn_bbox_loss: 0.1014 - mrcnn_class_loss: 0.0841 - mrcnn_bbox_loss: 0.0829 - mrcnn_mask_loss: 0.2599 - val_loss: 2.9270 - val_rpn_class_loss: 0.8908 - val_rpn_bbox_loss: 0.6014 - val_mrcnn_class_loss: 0.7254 - val_mrcnn_bbox_loss: 0.3647 - val_mrcnn_mask_loss: 0.3446\n",
      "Epoch 99/100\n",
      "146/146 [==============================] - 243s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5704 - rpn_class_loss: 0.0447 - rpn_bbox_loss: 0.1009 - mrcnn_class_loss: 0.0858 - mrcnn_bbox_loss: 0.0825 - mrcnn_mask_loss: 0.2565 - val_loss: 2.5989 - val_rpn_class_loss: 0.7382 - val_rpn_bbox_loss: 0.5593 - val_mrcnn_class_loss: 0.6012 - val_mrcnn_bbox_loss: 0.3499 - val_mrcnn_mask_loss: 0.3503\n",
      "Epoch 100/100\n",
      "146/146 [==============================] - 222s 2s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5489 - rpn_class_loss: 0.0400 - rpn_bbox_loss: 0.0952 - mrcnn_class_loss: 0.0806 - mrcnn_bbox_loss: 0.0794 - mrcnn_mask_loss: 0.2537 - val_loss: 2.7047 - val_rpn_class_loss: 0.7978 - val_rpn_bbox_loss: 0.5517 - val_mrcnn_class_loss: 0.6570 - val_mrcnn_bbox_loss: 0.3524 - val_mrcnn_mask_loss: 0.3458\n"
     ]
    }
   ],
   "source": [
    "# cargar dataset de entrenamiento\n",
    "train_set = DatasetArandanos()\n",
    "train_set.load_dataset(conjunto_datos, is_train=True)\n",
    "train_set.prepare()\n",
    "\n",
    "# cargar dataset de test \n",
    "test_set = DatasetArandanos()\n",
    "test_set.load_dataset(conjunto_datos, is_train=False)\n",
    "test_set.prepare()\n",
    "\n",
    "# preparar la configuración llamando a la clase de configuración definida por el usuario\n",
    "config = ConfigArandanos()\n",
    "\n",
    "\n",
    "# definir el modelo\n",
    "with tf.device(config.DEVICE):\n",
    "    model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "'''\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "'''\n",
    "\n",
    "# cargar pesos del modelo\n",
    "weights_path = pesos\n",
    "\n",
    "# cargar los pesos del modelo\n",
    "model.load_weights(weights_path, \n",
    "                   by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "#augmentation = iaa.Sequential(iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "#augmentation = iaa.Sometimes(5/6,iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "augmentation = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5)])\n",
    "#augmentation = iaa.Sometimes(5/6, iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "#augmentation = iaa.Sometimes(5/6, iaa.Fliplr(0.1), iaa.Flipud(0.1))\n",
    "\n",
    "# start the training of model\n",
    "# you can change epochs and layers (head or all)\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=100, layers='heads', augmentation=augmentation)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "master.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "da38062997892a68ae88df3a1549a85ff68f4e3a875c1f51aead31b07f2af4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
