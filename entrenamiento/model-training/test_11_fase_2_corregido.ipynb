{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 11 (paper) - Experimento 8 (PT)\n",
    "\n",
    "Entrenamiento de Mask R-CNN con dataset modificado para emular \"Test 11\"\n",
    "\n",
    "### Hiperparametros\n",
    "* **epoch = 120**\n",
    "    * steps x epoch = 146 (lotes de imagenes)\n",
    "    * batch = 2\n",
    "* optimizador = SGD\n",
    "* Funcion de perdida = SMOOTHL1LOSS\n",
    "* Metrica de evaluacion = mAP (IoU >= 0.5)\n",
    "* **Mini-mask shape: 28x28**\n",
    "* **RPN anchor scales: (8, 16, 32, 64, 128)**\n",
    "* Tasa de aprendizaje: 0.001\n",
    "* **imagenes = 305**\n",
    "    * entrenamiento 70% = 214\n",
    "    * validacion 30% = 91\n",
    "* etiquetas = 9140\n",
    "* **resolucion = 1920 x 1080**\n",
    "* etiquetas = bounding box formato VOC XML\n",
    "* **numero de clases = 2 (arandano, arandano-maduro)**\n",
    "* **data augmentation = false**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9csYdOiCeux-"
   },
   "source": [
    "## Comprobar directorio principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/PT_JoseVeloso/Mask_RCNN-master_matterport\r\n",
      "total 501708\r\n",
      "-rw-r--r--  1 root root      1095 Aug  9 19:45 LICENSE\r\n",
      "-rw-r--r--  1 root root        58 Aug  9 19:45 MANIFEST.in\r\n",
      "-rw-r--r--  1 root root     13771 Aug  9 19:45 README.md\r\n",
      "drwxr-xr-x  3 root root      4096 Aug  7 02:27 app\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 16 11:44 arandano_cfg_test_11_fase_2_20220916T0336\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 17 07:27 arandano_cfg_test_11_fase_2_20220917T0007\r\n",
      "drwxr-xr-x  4 root root     20480 Sep 11 22:26 arandano_cfg_test_5_20220907T0914\r\n",
      "drwxr-xr-x  3 root root     12288 Sep  9 15:19 arandano_cfg_test_5_20220909T0812\r\n",
      "drwxr-xr-x  5 root root     24576 Sep 18 21:32 arandano_cfg_test_5_2_20220917T0844\r\n",
      "drwxr-xr-x  3 root root     28672 Sep 15 00:32 arandano_cfg_test_5_fase_2_20220913T0749\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 20 07:32 arandano_cfg_test_5_fase_2_2_20220919T0845\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 13 02:17 arandano_cfg_test_6_20220912T1950\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 19 05:51 arandano_cfg_test_6_2_20220918T1934\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 15 15:03 arandano_cfg_test_6_fase_2_20220915T0216\r\n",
      "drwxr-xr-x  3 root root     12288 Sep 21 08:06 arandano_cfg_test_6_fase_2_2_20220920T0813\r\n",
      "drwxr-xr-x  2 root root      4096 Aug  7 02:27 assets\r\n",
      "drwxr-xr-x  4 root root      4096 Aug  7 02:27 build\r\n",
      "drwxr-xr-x 11 root root      4096 Sep 20 20:33 customImages\r\n",
      "drwxr-xr-x  4 root root      4096 Sep  7 03:36 damage_cfg_test_5_20220906T2000\r\n",
      "drwxr-xr-x  4 root root      4096 Sep 13 08:22 datasets\r\n",
      "drwxr-xr-x  2 root root      4096 Aug  7 02:27 dist\r\n",
      "drwxr-xr-x  2 root root      4096 Aug  7 02:27 images\r\n",
      "drwxr-xr-x  3 root root      4096 Sep 15 13:04 inspect\r\n",
      "drwxr-xr-x 19 root root      4096 Sep 19 07:07 logs\r\n",
      "drwxr-xr-x  2 root root      4096 Aug  9 19:48 mask_rcnn.egg-info\r\n",
      "-rw-r--r--  1 root root 255856928 Aug  7 02:27 mask_rcnn_balloon.h5\r\n",
      "-rw-r--r--  1 root root 257557808 Aug  7 02:27 mask_rcnn_coco.h5\r\n",
      "drwxr-xr-x  2 root root      4096 Aug  7 02:27 model\r\n",
      "drwxr-xr-x  8 root root      4096 Sep 21 08:12 model-training\r\n",
      "drwxr-xr-x  4 root root      4096 Aug  7 02:27 mrcnn\r\n",
      "-rw-r--r--  1 root root     37220 Aug 12 06:10 report.txt\r\n",
      "-rw-r--r--  1 root root       119 Aug  9 19:45 requirements.txt\r\n",
      "drwxr-xr-x  8 root root      4096 Sep  9 21:04 samples\r\n",
      "-rw-r--r--  1 root root        99 Aug  9 19:45 setup.cfg\r\n",
      "-rw-------  1 root root      2518 Sep  1 08:15 setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!pwd && ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6qajN7v0saE"
   },
   "source": [
    "# Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6812,
     "status": "ok",
     "timestamp": 1659596011947,
     "user": {
      "displayName": "José Ignacio Veloso Inzunza",
      "userId": "04140603416196179882"
     },
     "user_tz": 240
    },
    "id": "iyA_0ghC0saJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bibliotecas basicas\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "#sys.path.append(\"/tf/PT_JoseVeloso/Mask_RCNN-master/\")\n",
    "\n",
    "# bibliotecas avanzadas \n",
    "from xml.etree import ElementTree\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import imgaug\n",
    "\n",
    "# bibliotecas mask rcnn \n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn import visualize\n",
    "\n",
    "# biblioteca matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# bibliotecas numpy \n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "\n",
    "# bibliotecas keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img   #keras.preprocessing.image tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# ignorar alertas de elementos que seran descontinuados\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "%matplotlib inline\n",
    "#plt.show()\n",
    "\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Mbj3-t70saL"
   },
   "source": [
    "# Fase 2 - Entrenamiento con dos clases y etiquetas de Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGtz-ovS0saM"
   },
   "source": [
    "En este entremamiento se utiliza un conjunto de datos simple con imágenes etiquetadas con cuadros delimitadores y una clase llamada 'Daño'. En la siguiente sección se encuentra el código para el entrenamiento del modelo. Se incluyen comentarios para describir mejor el flujo del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetArandanos(Dataset):\n",
    "    \n",
    "    # la funcion load_dataset es usada para cargar el dataset de entrenamiento y test\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        \n",
    "        # se agrega una clase que se necesita para clasificar, en este caso arandano\n",
    "        # self.add_class('source', 'class id', 'class name')\n",
    "        self.add_class(\"dataset\", 1, \"arandano\")\n",
    "        self.add_class(\"dataset\", 2, \"arandano-maduro\")\n",
    "        #self.add_class(\"dataset\", 3, \"arandano-pinton\")\n",
    "        #self.add_class(\"dataset\", 4, \"arandano-semi\")\n",
    "        \n",
    "        # se concatena dataset_dir con /images y /annots\n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annots/'\n",
    "        \n",
    "        # is_train sera Verdadero si se esta entrenando el modelo y Falso si se esta testeando el modelo\n",
    "        for filename in listdir(images_dir):\n",
    "            \n",
    "            # extract image id\n",
    "            image_id = filename[:-4] # se usa para omitir los últimos 4 caracteres: '.jpg' (en class_id.jpg)\n",
    "            \n",
    "            # si is_train es Verdadero se omiten todas las imágenes con id mayor que e iguales a 11074\n",
    "            # aproximadamente el 80% del conjunto de datos es para entrenamiento\n",
    "            if is_train and int(image_id) >= 40450 :\n",
    "                #print(\"image_id: \", image_id)\n",
    "                continue\n",
    "             \n",
    "            # si is_train no es Verdadero se omiten todas las imágenes con id menores a 11074\n",
    "            if not is_train and int(image_id) < 40450:\n",
    "                continue\n",
    "            \n",
    "            # se declara la ruta de la imagen y la ruta de las etiquetas \n",
    "            img_path = images_dir + filename\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            \n",
    "            # usando la función add_image se pasan image_id, image_path y ann_path para que la \n",
    "            # imagen actual se agregue al conjunto de datos para entrenamiento o prueba\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "    # funcino usada para extraer bouding boxes desde archivos etiquetados \n",
    "    def extract_boxes(self, filename):\n",
    "\n",
    "        # se puede ver en las imágenes que estan etiquetadas, como se extraen los valores de ancho, alto y bndbox\n",
    "\n",
    "        # <size>\n",
    "\n",
    "        #       <width>640</width>\n",
    "\n",
    "        #       <height>360</height>\n",
    "\n",
    "        #       <depth>3</depth>\n",
    "\n",
    "        # </size>\n",
    "\n",
    "\n",
    "        # <object>\n",
    "\n",
    "        #          <name>damage</name>\n",
    "\n",
    "        #          <pose>Unspecified</pose>\n",
    "\n",
    "        #          <truncated>0</truncated>\n",
    "\n",
    "        #          <difficult>0</difficult>\n",
    "\n",
    "\n",
    "        #          <bndbox>\n",
    "\n",
    "        #                 <xmin>315</xmin>\n",
    "\n",
    "        #                 <ymin>160</ymin>\n",
    "\n",
    "        #                 <xmax>381</xmax>\n",
    "\n",
    "        #                 <ymax>199</ymax>\n",
    "\n",
    "        #          </bndbox>\n",
    "\n",
    "        # </object>\n",
    "\n",
    "        # </annotation>\n",
    "        \n",
    "        # para analizar los archivos .xml\n",
    "        tree = ElementTree.parse(filename)\n",
    "        \n",
    "        # para obtener la raíz del archivo xml\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # se agregan todas las coordenadas x, y en boxes para todas las instancias de un objeto\n",
    "        boxes = list()\n",
    "        \n",
    "        # se encuentran todos los atributos con el nombre bndbox que existan para cada ground truth en la imagen\n",
    "        for box in root.findall('.//object'):\n",
    "            name = box.find('name').text\n",
    "            xmin = int(box.find('./bndbox/xmin').text)\n",
    "            ymin = int(box.find('./bndbox/ymin').text)\n",
    "            xmax = int(box.find('./bndbox/xmax').text)\n",
    "            ymax = int(box.find('./bndbox/ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax, name]\n",
    "            boxes.append(coors)\n",
    "                        \n",
    "            #quita todas las imagenes no etiquetadas\n",
    "            if name=='arandano' or name=='arandano-maduro':\n",
    "                boxes.append(coors)\n",
    "\n",
    "        # extraer ancho y alto de la imagen\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        \n",
    "        # retorna boxes-> list, width-> int y height-> int \n",
    "        return boxes, width, height\n",
    "    \n",
    "    # esta función llama al método extract_boxes y se usa para cargar una máscara para cada instancia en una imagen \n",
    "    # devuelve una máscara booleana con las siguientes dimensiones ancho * alto * instancias\n",
    "    def load_mask(self, image_id):\n",
    "        \n",
    "        # info apunta al image_id actual \n",
    "        info = self.image_info[image_id]\n",
    "        \n",
    "        # se obtiene la ruta de anotación de image_id que es dataset_dir/annots/image_id.xml \n",
    "        path = info['annotation']\n",
    "        \n",
    "         # se llama al método extract_boxes (arriba) para obtener bndbox del archivo .xml\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        \n",
    "        # se crea una cantidad de len(boxes) de mascaras de alto 'h' y ancho 'w'\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\n",
    "        class_ids = list()\n",
    "        \n",
    "        ## se recorren todos los boxes y generamos máscaras (máscara de bndbox) y class id para cada instancia\n",
    "        # las máscaras tendrán forma rectangular ya que hemos usado bndboxes para etiquetas\n",
    "        # por ejemplo: si 2.jpg tiene tres objetos, tendremos las siguientes máscaras y class_ids.\n",
    "        \n",
    "        # 000000000 000000000 000003330 111100000\n",
    "        # 000011100 022200000 000003330 111100000\n",
    "        # 000011100 022200000 000003330 111100000\n",
    "        # 000000000 022200000 000000000 000000000\n",
    "        #    1         2          3         1<- class_ids\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            \n",
    "            # box[4] will have the name of the class for a particular damage\n",
    "            if (box[4] == 'arandano'):\n",
    "                masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "                class_ids.append(self.class_names.index('arandano'))\n",
    "            elif(box[4] == 'arandano-maduro'):\n",
    "                masks[row_s:row_e, col_s:col_e, i] = 2\n",
    "                class_ids.append(self.class_names.index('arandano-maduro')) \n",
    "                \n",
    "        # retorna mascaras y class_ids como arreglo\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "    \n",
    "    # esta funciones toma el image_id y retorna la ruta de la imagen \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DEVICE                         /gpu:0\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.8\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (28, 28)\n",
      "NAME                           arandano_cfg_test_11_fase_2_2_\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 1.5]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                146\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "Train_ROIs_Per_Image           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# damage configuration class, you can change values of hyper parameters here\n",
    "class ConfigArandanos(Config):\n",
    "\n",
    "    # nombre de la configuracion\n",
    "    NAME = \"arandano_cfg_test_11_fase_2_2_\"    \n",
    "    \n",
    "    # clase arandano + clase background + 4 clases\n",
    "    NUM_CLASSES = 1 + 2\n",
    "    \n",
    "    # pasos por epoch y confianza minima    # STEPS_PER_EPOCH = cantidad de lotes/batchs\n",
    "    STEPS_PER_EPOCH = 146  # por epoch se entrenaran 61 lotes de 5 imagenes, dataset = 305\n",
    "\n",
    "    # tasa de aprendizaje y momentum\n",
    "    LEARNING_RATE=0.001\n",
    "    LEARNING_MOMENTUM = 0.8\n",
    "    \n",
    "    # penalización de regularización\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    \n",
    "    # el tamaño de la imagen está controlado por este parámetro\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    \n",
    "    # pasos de validación\n",
    "    VALIDATION_STEPS = 50\n",
    "    \n",
    "    # número de regiones de interés generadas por imagen\n",
    "    Train_ROIs_Per_Image = 200\n",
    "    \n",
    "    # escala de anclas RPN y proporciones (ratios) para encontrar la ROI\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)    # Longitud del lado del ancla cuadrada, en píxeles \n",
    "    RPN_ANCHOR_RATIOS = [0.5, 1, 1.5]   # Proporciones de anclas por cada celda (ancho/alto). Un valor de 1 representa un ancla cuadrada y 0,5 es un ancla ancha \n",
    "\n",
    "    #DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0    \n",
    "    DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "    MINI_MASK_SHAPE = (28, 28)\n",
    "    \n",
    "ConfigArandanos().display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/PT_JoseVeloso/Mask_RCNN-master_matterport\n"
     ]
    }
   ],
   "source": [
    "cd /tf/PT_JoseVeloso/Mask_RCNN-master_matterport/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pesos = 'mask_rcnn_coco.h5'\n",
    "#pesos = 'mask_rcnn_damage_cfg_0049.h5'\n",
    "#pesos = 'arandano_cfg_test_5_20220907T0914/mask_rcnn_arandano_cfg_0300.h5'\n",
    "#pesos = 'arandano_cfg_test_5_20220907T0914/mask_rcnn_arandano_cfg_0300.h5'\n",
    "pesos = 'arandano_cfg_test_6_fase_2_2_20220920T0813/mask_rcnn_arandano_cfg_test_6_fase_2_2__0120.h5'\n",
    "\n",
    "conjunto_datos = 'customImages/test_11_fase_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3787125,
     "status": "ok",
     "timestamp": 1659604139130,
     "user": {
      "displayName": "José Ignacio Veloso Inzunza",
      "userId": "04140603416196179882"
     },
     "user_tz": 240
    },
    "id": "dF77APDH0saM",
    "outputId": "aa2a0330-e201-4b00-b12c-fee7986449cb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./arandano_cfg_test_11_fase_2_2_20220921T0813/mask_rcnn_arandano_cfg_test_11_fase_2_2__{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (AnchorsLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier_1/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask_1/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_2_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_2_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32, device=/device:GPU:0))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_3_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_3_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI_1/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32, device=/device:GPU:0))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - ETA: 0s - batch: 72.5000 - size: 2.0000 - loss: 2.9067 - rpn_class_loss: 0.2281 - rpn_bbox_loss: 1.2188 - mrcnn_class_loss: 0.1731 - mrcnn_bbox_loss: 0.7808 - mrcnn_mask_loss: 0.5059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 707s 5s/step - batch: 72.5000 - size: 2.0000 - loss: 2.9067 - rpn_class_loss: 0.2281 - rpn_bbox_loss: 1.2188 - mrcnn_class_loss: 0.1731 - mrcnn_bbox_loss: 0.7808 - mrcnn_mask_loss: 0.5059 - val_loss: 2.3238 - val_rpn_class_loss: 0.3101 - val_rpn_bbox_loss: 0.7490 - val_mrcnn_class_loss: 0.1814 - val_mrcnn_bbox_loss: 0.5669 - val_mrcnn_mask_loss: 0.5164\n",
      "Epoch 2/120\n",
      "146/146 [==============================] - 525s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.8195 - rpn_class_loss: 0.1016 - rpn_bbox_loss: 0.6504 - mrcnn_class_loss: 0.1324 - mrcnn_bbox_loss: 0.4503 - mrcnn_mask_loss: 0.4847 - val_loss: 2.1404 - val_rpn_class_loss: 0.2203 - val_rpn_bbox_loss: 0.7326 - val_mrcnn_class_loss: 0.1710 - val_mrcnn_bbox_loss: 0.5240 - val_mrcnn_mask_loss: 0.4925\n",
      "Epoch 3/120\n",
      "146/146 [==============================] - 630s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.6549 - rpn_class_loss: 0.0780 - rpn_bbox_loss: 0.5959 - mrcnn_class_loss: 0.1531 - mrcnn_bbox_loss: 0.3804 - mrcnn_mask_loss: 0.4475 - val_loss: 2.2345 - val_rpn_class_loss: 0.3548 - val_rpn_bbox_loss: 0.6748 - val_mrcnn_class_loss: 0.2516 - val_mrcnn_bbox_loss: 0.4777 - val_mrcnn_mask_loss: 0.4756\n",
      "Epoch 4/120\n",
      "146/146 [==============================] - 521s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.6446 - rpn_class_loss: 0.0802 - rpn_bbox_loss: 0.5964 - mrcnn_class_loss: 0.1785 - mrcnn_bbox_loss: 0.3555 - mrcnn_mask_loss: 0.4339 - val_loss: 2.0489 - val_rpn_class_loss: 0.2181 - val_rpn_bbox_loss: 0.7459 - val_mrcnn_class_loss: 0.2071 - val_mrcnn_bbox_loss: 0.4199 - val_mrcnn_mask_loss: 0.4579\n",
      "Epoch 5/120\n",
      "146/146 [==============================] - 599s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.5506 - rpn_class_loss: 0.0750 - rpn_bbox_loss: 0.5448 - mrcnn_class_loss: 0.1927 - mrcnn_bbox_loss: 0.3169 - mrcnn_mask_loss: 0.4211 - val_loss: 1.9622 - val_rpn_class_loss: 0.1630 - val_rpn_bbox_loss: 0.6445 - val_mrcnn_class_loss: 0.2911 - val_mrcnn_bbox_loss: 0.4231 - val_mrcnn_mask_loss: 0.4405\n",
      "Epoch 6/120\n",
      "146/146 [==============================] - 651s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.4911 - rpn_class_loss: 0.0692 - rpn_bbox_loss: 0.4838 - mrcnn_class_loss: 0.2219 - mrcnn_bbox_loss: 0.3066 - mrcnn_mask_loss: 0.4095 - val_loss: 2.1186 - val_rpn_class_loss: 0.2525 - val_rpn_bbox_loss: 0.6818 - val_mrcnn_class_loss: 0.3504 - val_mrcnn_bbox_loss: 0.4028 - val_mrcnn_mask_loss: 0.4309\n",
      "Epoch 7/120\n",
      "146/146 [==============================] - 557s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.4404 - rpn_class_loss: 0.0682 - rpn_bbox_loss: 0.4473 - mrcnn_class_loss: 0.2300 - mrcnn_bbox_loss: 0.2907 - mrcnn_mask_loss: 0.4043 - val_loss: 2.0517 - val_rpn_class_loss: 0.2100 - val_rpn_bbox_loss: 0.6221 - val_mrcnn_class_loss: 0.3365 - val_mrcnn_bbox_loss: 0.4438 - val_mrcnn_mask_loss: 0.4393\n",
      "Epoch 8/120\n",
      "146/146 [==============================] - 556s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.3489 - rpn_class_loss: 0.0592 - rpn_bbox_loss: 0.3823 - mrcnn_class_loss: 0.2378 - mrcnn_bbox_loss: 0.2739 - mrcnn_mask_loss: 0.3957 - val_loss: 2.0394 - val_rpn_class_loss: 0.1926 - val_rpn_bbox_loss: 0.6437 - val_mrcnn_class_loss: 0.3892 - val_mrcnn_bbox_loss: 0.3912 - val_mrcnn_mask_loss: 0.4227\n",
      "Epoch 9/120\n",
      "146/146 [==============================] - 579s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2537 - rpn_class_loss: 0.0595 - rpn_bbox_loss: 0.3338 - mrcnn_class_loss: 0.2246 - mrcnn_bbox_loss: 0.2520 - mrcnn_mask_loss: 0.3837 - val_loss: 1.9473 - val_rpn_class_loss: 0.1767 - val_rpn_bbox_loss: 0.6242 - val_mrcnn_class_loss: 0.3662 - val_mrcnn_bbox_loss: 0.3672 - val_mrcnn_mask_loss: 0.4129\n",
      "Epoch 10/120\n",
      "146/146 [==============================] - 582s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.2648 - rpn_class_loss: 0.0513 - rpn_bbox_loss: 0.3160 - mrcnn_class_loss: 0.2589 - mrcnn_bbox_loss: 0.2555 - mrcnn_mask_loss: 0.3831 - val_loss: 1.9939 - val_rpn_class_loss: 0.2254 - val_rpn_bbox_loss: 0.6408 - val_mrcnn_class_loss: 0.3613 - val_mrcnn_bbox_loss: 0.3606 - val_mrcnn_mask_loss: 0.4059\n",
      "Epoch 11/120\n",
      "146/146 [==============================] - 572s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1906 - rpn_class_loss: 0.0555 - rpn_bbox_loss: 0.2759 - mrcnn_class_loss: 0.2383 - mrcnn_bbox_loss: 0.2408 - mrcnn_mask_loss: 0.3801 - val_loss: 2.1236 - val_rpn_class_loss: 0.2763 - val_rpn_bbox_loss: 0.6950 - val_mrcnn_class_loss: 0.3936 - val_mrcnn_bbox_loss: 0.3496 - val_mrcnn_mask_loss: 0.4090\n",
      "Epoch 12/120\n",
      "146/146 [==============================] - 507s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 1.1736 - rpn_class_loss: 0.0524 - rpn_bbox_loss: 0.2597 - mrcnn_class_loss: 0.2493 - mrcnn_bbox_loss: 0.2350 - mrcnn_mask_loss: 0.3771 - val_loss: 1.9984 - val_rpn_class_loss: 0.2414 - val_rpn_bbox_loss: 0.6073 - val_mrcnn_class_loss: 0.3798 - val_mrcnn_bbox_loss: 0.3737 - val_mrcnn_mask_loss: 0.3963\n",
      "Epoch 13/120\n",
      "146/146 [==============================] - 581s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0864 - rpn_class_loss: 0.0499 - rpn_bbox_loss: 0.2126 - mrcnn_class_loss: 0.2405 - mrcnn_bbox_loss: 0.2154 - mrcnn_mask_loss: 0.3680 - val_loss: 1.9229 - val_rpn_class_loss: 0.1572 - val_rpn_bbox_loss: 0.6449 - val_mrcnn_class_loss: 0.3882 - val_mrcnn_bbox_loss: 0.3330 - val_mrcnn_mask_loss: 0.3997\n",
      "Epoch 14/120\n",
      "146/146 [==============================] - 640s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0536 - rpn_class_loss: 0.0496 - rpn_bbox_loss: 0.1890 - mrcnn_class_loss: 0.2305 - mrcnn_bbox_loss: 0.2117 - mrcnn_mask_loss: 0.3727 - val_loss: 1.9934 - val_rpn_class_loss: 0.1775 - val_rpn_bbox_loss: 0.6371 - val_mrcnn_class_loss: 0.4374 - val_mrcnn_bbox_loss: 0.3501 - val_mrcnn_mask_loss: 0.3911\n",
      "Epoch 15/120\n",
      "146/146 [==============================] - 584s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 1.0612 - rpn_class_loss: 0.0464 - rpn_bbox_loss: 0.1924 - mrcnn_class_loss: 0.2461 - mrcnn_bbox_loss: 0.2123 - mrcnn_mask_loss: 0.3640 - val_loss: 1.9459 - val_rpn_class_loss: 0.1712 - val_rpn_bbox_loss: 0.6058 - val_mrcnn_class_loss: 0.4261 - val_mrcnn_bbox_loss: 0.3530 - val_mrcnn_mask_loss: 0.3897\n",
      "Epoch 16/120\n",
      "146/146 [==============================] - 576s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9876 - rpn_class_loss: 0.0417 - rpn_bbox_loss: 0.1519 - mrcnn_class_loss: 0.2331 - mrcnn_bbox_loss: 0.2025 - mrcnn_mask_loss: 0.3584 - val_loss: 1.9664 - val_rpn_class_loss: 0.1856 - val_rpn_bbox_loss: 0.6754 - val_mrcnn_class_loss: 0.3780 - val_mrcnn_bbox_loss: 0.3398 - val_mrcnn_mask_loss: 0.3877\n",
      "Epoch 17/120\n",
      "146/146 [==============================] - 623s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9518 - rpn_class_loss: 0.0394 - rpn_bbox_loss: 0.1339 - mrcnn_class_loss: 0.2229 - mrcnn_bbox_loss: 0.1977 - mrcnn_mask_loss: 0.3580 - val_loss: 1.9763 - val_rpn_class_loss: 0.2040 - val_rpn_bbox_loss: 0.6444 - val_mrcnn_class_loss: 0.4015 - val_mrcnn_bbox_loss: 0.3336 - val_mrcnn_mask_loss: 0.3927\n",
      "Epoch 18/120\n",
      "146/146 [==============================] - 538s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9418 - rpn_class_loss: 0.0419 - rpn_bbox_loss: 0.1313 - mrcnn_class_loss: 0.2268 - mrcnn_bbox_loss: 0.1859 - mrcnn_mask_loss: 0.3560 - val_loss: 1.9536 - val_rpn_class_loss: 0.2181 - val_rpn_bbox_loss: 0.6166 - val_mrcnn_class_loss: 0.4139 - val_mrcnn_bbox_loss: 0.3315 - val_mrcnn_mask_loss: 0.3736\n",
      "Epoch 19/120\n",
      "146/146 [==============================] - 561s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.9149 - rpn_class_loss: 0.0378 - rpn_bbox_loss: 0.1203 - mrcnn_class_loss: 0.2178 - mrcnn_bbox_loss: 0.1853 - mrcnn_mask_loss: 0.3538 - val_loss: 1.9212 - val_rpn_class_loss: 0.1794 - val_rpn_bbox_loss: 0.6677 - val_mrcnn_class_loss: 0.3664 - val_mrcnn_bbox_loss: 0.3262 - val_mrcnn_mask_loss: 0.3816\n",
      "Epoch 20/120\n",
      "146/146 [==============================] - 638s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8542 - rpn_class_loss: 0.0330 - rpn_bbox_loss: 0.1047 - mrcnn_class_loss: 0.1972 - mrcnn_bbox_loss: 0.1716 - mrcnn_mask_loss: 0.3477 - val_loss: 2.0001 - val_rpn_class_loss: 0.1968 - val_rpn_bbox_loss: 0.6434 - val_mrcnn_class_loss: 0.4459 - val_mrcnn_bbox_loss: 0.3331 - val_mrcnn_mask_loss: 0.3809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120\n",
      "146/146 [==============================] - 582s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8682 - rpn_class_loss: 0.0352 - rpn_bbox_loss: 0.1033 - mrcnn_class_loss: 0.2027 - mrcnn_bbox_loss: 0.1779 - mrcnn_mask_loss: 0.3493 - val_loss: 1.9378 - val_rpn_class_loss: 0.2214 - val_rpn_bbox_loss: 0.6124 - val_mrcnn_class_loss: 0.4109 - val_mrcnn_bbox_loss: 0.3312 - val_mrcnn_mask_loss: 0.3621\n",
      "Epoch 22/120\n",
      "146/146 [==============================] - 580s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.8225 - rpn_class_loss: 0.0340 - rpn_bbox_loss: 0.0980 - mrcnn_class_loss: 0.1818 - mrcnn_bbox_loss: 0.1666 - mrcnn_mask_loss: 0.3421 - val_loss: 2.0047 - val_rpn_class_loss: 0.2424 - val_rpn_bbox_loss: 0.6697 - val_mrcnn_class_loss: 0.3945 - val_mrcnn_bbox_loss: 0.3225 - val_mrcnn_mask_loss: 0.3755\n",
      "Epoch 23/120\n",
      "146/146 [==============================] - 531s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7999 - rpn_class_loss: 0.0330 - rpn_bbox_loss: 0.0915 - mrcnn_class_loss: 0.1801 - mrcnn_bbox_loss: 0.1570 - mrcnn_mask_loss: 0.3383 - val_loss: 2.0760 - val_rpn_class_loss: 0.2454 - val_rpn_bbox_loss: 0.7465 - val_mrcnn_class_loss: 0.3810 - val_mrcnn_bbox_loss: 0.3278 - val_mrcnn_mask_loss: 0.3753\n",
      "Epoch 24/120\n",
      "146/146 [==============================] - 500s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7792 - rpn_class_loss: 0.0298 - rpn_bbox_loss: 0.0810 - mrcnn_class_loss: 0.1728 - mrcnn_bbox_loss: 0.1594 - mrcnn_mask_loss: 0.3362 - val_loss: 2.0790 - val_rpn_class_loss: 0.2544 - val_rpn_bbox_loss: 0.7480 - val_mrcnn_class_loss: 0.3596 - val_mrcnn_bbox_loss: 0.3329 - val_mrcnn_mask_loss: 0.3841\n",
      "Epoch 25/120\n",
      "146/146 [==============================] - 579s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7804 - rpn_class_loss: 0.0311 - rpn_bbox_loss: 0.0861 - mrcnn_class_loss: 0.1751 - mrcnn_bbox_loss: 0.1541 - mrcnn_mask_loss: 0.3340 - val_loss: 1.9001 - val_rpn_class_loss: 0.2163 - val_rpn_bbox_loss: 0.6426 - val_mrcnn_class_loss: 0.3546 - val_mrcnn_bbox_loss: 0.3169 - val_mrcnn_mask_loss: 0.3697\n",
      "Epoch 26/120\n",
      "146/146 [==============================] - 521s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7564 - rpn_class_loss: 0.0339 - rpn_bbox_loss: 0.0880 - mrcnn_class_loss: 0.1599 - mrcnn_bbox_loss: 0.1476 - mrcnn_mask_loss: 0.3270 - val_loss: 1.9234 - val_rpn_class_loss: 0.2331 - val_rpn_bbox_loss: 0.6511 - val_mrcnn_class_loss: 0.3701 - val_mrcnn_bbox_loss: 0.3062 - val_mrcnn_mask_loss: 0.3628\n",
      "Epoch 27/120\n",
      "146/146 [==============================] - 608s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7290 - rpn_class_loss: 0.0308 - rpn_bbox_loss: 0.0729 - mrcnn_class_loss: 0.1633 - mrcnn_bbox_loss: 0.1399 - mrcnn_mask_loss: 0.3221 - val_loss: 2.1526 - val_rpn_class_loss: 0.2571 - val_rpn_bbox_loss: 0.7440 - val_mrcnn_class_loss: 0.4394 - val_mrcnn_bbox_loss: 0.3187 - val_mrcnn_mask_loss: 0.3935\n",
      "Epoch 28/120\n",
      "146/146 [==============================] - 592s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7243 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.0739 - mrcnn_class_loss: 0.1573 - mrcnn_bbox_loss: 0.1379 - mrcnn_mask_loss: 0.3237 - val_loss: 2.0393 - val_rpn_class_loss: 0.1947 - val_rpn_bbox_loss: 0.7603 - val_mrcnn_class_loss: 0.3817 - val_mrcnn_bbox_loss: 0.3251 - val_mrcnn_mask_loss: 0.3776\n",
      "Epoch 29/120\n",
      "146/146 [==============================] - 541s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.7179 - rpn_class_loss: 0.0303 - rpn_bbox_loss: 0.0669 - mrcnn_class_loss: 0.1602 - mrcnn_bbox_loss: 0.1389 - mrcnn_mask_loss: 0.3216 - val_loss: 1.9993 - val_rpn_class_loss: 0.2591 - val_rpn_bbox_loss: 0.6926 - val_mrcnn_class_loss: 0.3657 - val_mrcnn_bbox_loss: 0.3154 - val_mrcnn_mask_loss: 0.3665\n",
      "Epoch 30/120\n",
      "146/146 [==============================] - 556s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6910 - rpn_class_loss: 0.0264 - rpn_bbox_loss: 0.0619 - mrcnn_class_loss: 0.1516 - mrcnn_bbox_loss: 0.1298 - mrcnn_mask_loss: 0.3214 - val_loss: 1.9622 - val_rpn_class_loss: 0.2543 - val_rpn_bbox_loss: 0.6543 - val_mrcnn_class_loss: 0.3875 - val_mrcnn_bbox_loss: 0.3067 - val_mrcnn_mask_loss: 0.3595\n",
      "Epoch 31/120\n",
      "146/146 [==============================] - 624s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6794 - rpn_class_loss: 0.0269 - rpn_bbox_loss: 0.0613 - mrcnn_class_loss: 0.1486 - mrcnn_bbox_loss: 0.1290 - mrcnn_mask_loss: 0.3137 - val_loss: 2.0054 - val_rpn_class_loss: 0.2821 - val_rpn_bbox_loss: 0.6894 - val_mrcnn_class_loss: 0.3593 - val_mrcnn_bbox_loss: 0.3013 - val_mrcnn_mask_loss: 0.3733\n",
      "Epoch 32/120\n",
      "146/146 [==============================] - 567s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6591 - rpn_class_loss: 0.0259 - rpn_bbox_loss: 0.0542 - mrcnn_class_loss: 0.1388 - mrcnn_bbox_loss: 0.1254 - mrcnn_mask_loss: 0.3148 - val_loss: 2.0743 - val_rpn_class_loss: 0.3362 - val_rpn_bbox_loss: 0.7048 - val_mrcnn_class_loss: 0.3632 - val_mrcnn_bbox_loss: 0.3034 - val_mrcnn_mask_loss: 0.3668\n",
      "Epoch 33/120\n",
      "146/146 [==============================] - 592s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6542 - rpn_class_loss: 0.0240 - rpn_bbox_loss: 0.0594 - mrcnn_class_loss: 0.1347 - mrcnn_bbox_loss: 0.1224 - mrcnn_mask_loss: 0.3137 - val_loss: 2.0730 - val_rpn_class_loss: 0.2503 - val_rpn_bbox_loss: 0.7080 - val_mrcnn_class_loss: 0.4259 - val_mrcnn_bbox_loss: 0.3160 - val_mrcnn_mask_loss: 0.3728\n",
      "Epoch 34/120\n",
      "146/146 [==============================] - 460s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6577 - rpn_class_loss: 0.0258 - rpn_bbox_loss: 0.0570 - mrcnn_class_loss: 0.1399 - mrcnn_bbox_loss: 0.1222 - mrcnn_mask_loss: 0.3128 - val_loss: 1.9986 - val_rpn_class_loss: 0.2428 - val_rpn_bbox_loss: 0.6710 - val_mrcnn_class_loss: 0.4207 - val_mrcnn_bbox_loss: 0.3098 - val_mrcnn_mask_loss: 0.3542\n",
      "Epoch 35/120\n",
      "146/146 [==============================] - 523s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6309 - rpn_class_loss: 0.0251 - rpn_bbox_loss: 0.0513 - mrcnn_class_loss: 0.1335 - mrcnn_bbox_loss: 0.1146 - mrcnn_mask_loss: 0.3064 - val_loss: 2.0165 - val_rpn_class_loss: 0.2302 - val_rpn_bbox_loss: 0.7263 - val_mrcnn_class_loss: 0.4036 - val_mrcnn_bbox_loss: 0.3063 - val_mrcnn_mask_loss: 0.3501\n",
      "Epoch 36/120\n",
      "146/146 [==============================] - 566s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6079 - rpn_class_loss: 0.0224 - rpn_bbox_loss: 0.0463 - mrcnn_class_loss: 0.1216 - mrcnn_bbox_loss: 0.1112 - mrcnn_mask_loss: 0.3064 - val_loss: 2.0504 - val_rpn_class_loss: 0.2341 - val_rpn_bbox_loss: 0.7142 - val_mrcnn_class_loss: 0.4324 - val_mrcnn_bbox_loss: 0.3119 - val_mrcnn_mask_loss: 0.3577\n",
      "Epoch 37/120\n",
      "146/146 [==============================] - 497s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6098 - rpn_class_loss: 0.0213 - rpn_bbox_loss: 0.0561 - mrcnn_class_loss: 0.1197 - mrcnn_bbox_loss: 0.1115 - mrcnn_mask_loss: 0.3012 - val_loss: 2.0560 - val_rpn_class_loss: 0.2756 - val_rpn_bbox_loss: 0.6939 - val_mrcnn_class_loss: 0.4378 - val_mrcnn_bbox_loss: 0.2943 - val_mrcnn_mask_loss: 0.3544\n",
      "Epoch 38/120\n",
      "146/146 [==============================] - 540s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.6078 - rpn_class_loss: 0.0238 - rpn_bbox_loss: 0.0554 - mrcnn_class_loss: 0.1187 - mrcnn_bbox_loss: 0.1081 - mrcnn_mask_loss: 0.3018 - val_loss: 2.0601 - val_rpn_class_loss: 0.2644 - val_rpn_bbox_loss: 0.7120 - val_mrcnn_class_loss: 0.4354 - val_mrcnn_bbox_loss: 0.2936 - val_mrcnn_mask_loss: 0.3547\n",
      "Epoch 39/120\n",
      "146/146 [==============================] - 657s 5s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5794 - rpn_class_loss: 0.0229 - rpn_bbox_loss: 0.0515 - mrcnn_class_loss: 0.1111 - mrcnn_bbox_loss: 0.1017 - mrcnn_mask_loss: 0.2922 - val_loss: 2.1487 - val_rpn_class_loss: 0.3161 - val_rpn_bbox_loss: 0.7467 - val_mrcnn_class_loss: 0.4185 - val_mrcnn_bbox_loss: 0.2991 - val_mrcnn_mask_loss: 0.3682\n",
      "Epoch 40/120\n",
      "146/146 [==============================] - 607s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5866 - rpn_class_loss: 0.0214 - rpn_bbox_loss: 0.0513 - mrcnn_class_loss: 0.1085 - mrcnn_bbox_loss: 0.1070 - mrcnn_mask_loss: 0.2983 - val_loss: 2.3753 - val_rpn_class_loss: 0.4700 - val_rpn_bbox_loss: 0.7878 - val_mrcnn_class_loss: 0.4709 - val_mrcnn_bbox_loss: 0.2902 - val_mrcnn_mask_loss: 0.3564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/120\n",
      "146/146 [==============================] - 577s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5676 - rpn_class_loss: 0.0211 - rpn_bbox_loss: 0.0435 - mrcnn_class_loss: 0.1086 - mrcnn_bbox_loss: 0.0992 - mrcnn_mask_loss: 0.2951 - val_loss: 2.1278 - val_rpn_class_loss: 0.3046 - val_rpn_bbox_loss: 0.7827 - val_mrcnn_class_loss: 0.3965 - val_mrcnn_bbox_loss: 0.2931 - val_mrcnn_mask_loss: 0.3509\n",
      "Epoch 42/120\n",
      "146/146 [==============================] - 660s 5s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5512 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.0412 - mrcnn_class_loss: 0.1040 - mrcnn_bbox_loss: 0.0969 - mrcnn_mask_loss: 0.2889 - val_loss: 2.1284 - val_rpn_class_loss: 0.2961 - val_rpn_bbox_loss: 0.7588 - val_mrcnn_class_loss: 0.4327 - val_mrcnn_bbox_loss: 0.2897 - val_mrcnn_mask_loss: 0.3511\n",
      "Epoch 43/120\n",
      "146/146 [==============================] - 520s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5461 - rpn_class_loss: 0.0210 - rpn_bbox_loss: 0.0449 - mrcnn_class_loss: 0.1004 - mrcnn_bbox_loss: 0.0967 - mrcnn_mask_loss: 0.2833 - val_loss: 2.2295 - val_rpn_class_loss: 0.3262 - val_rpn_bbox_loss: 0.7940 - val_mrcnn_class_loss: 0.4517 - val_mrcnn_bbox_loss: 0.3014 - val_mrcnn_mask_loss: 0.3561\n",
      "Epoch 44/120\n",
      "146/146 [==============================] - 596s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5311 - rpn_class_loss: 0.0174 - rpn_bbox_loss: 0.0441 - mrcnn_class_loss: 0.0932 - mrcnn_bbox_loss: 0.0913 - mrcnn_mask_loss: 0.2851 - val_loss: 2.0099 - val_rpn_class_loss: 0.2834 - val_rpn_bbox_loss: 0.6862 - val_mrcnn_class_loss: 0.3975 - val_mrcnn_bbox_loss: 0.2927 - val_mrcnn_mask_loss: 0.3501\n",
      "Epoch 45/120\n",
      "146/146 [==============================] - 523s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5367 - rpn_class_loss: 0.0199 - rpn_bbox_loss: 0.0492 - mrcnn_class_loss: 0.0910 - mrcnn_bbox_loss: 0.0937 - mrcnn_mask_loss: 0.2830 - val_loss: 2.0260 - val_rpn_class_loss: 0.2630 - val_rpn_bbox_loss: 0.7371 - val_mrcnn_class_loss: 0.3776 - val_mrcnn_bbox_loss: 0.2852 - val_mrcnn_mask_loss: 0.3630\n",
      "Epoch 46/120\n",
      "146/146 [==============================] - 552s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5366 - rpn_class_loss: 0.0192 - rpn_bbox_loss: 0.0458 - mrcnn_class_loss: 0.0965 - mrcnn_bbox_loss: 0.0924 - mrcnn_mask_loss: 0.2827 - val_loss: 2.0194 - val_rpn_class_loss: 0.2761 - val_rpn_bbox_loss: 0.6471 - val_mrcnn_class_loss: 0.4509 - val_mrcnn_bbox_loss: 0.2913 - val_mrcnn_mask_loss: 0.3541\n",
      "Epoch 47/120\n",
      "146/146 [==============================] - 649s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5145 - rpn_class_loss: 0.0175 - rpn_bbox_loss: 0.0389 - mrcnn_class_loss: 0.0924 - mrcnn_bbox_loss: 0.0886 - mrcnn_mask_loss: 0.2771 - val_loss: 2.2085 - val_rpn_class_loss: 0.3612 - val_rpn_bbox_loss: 0.6973 - val_mrcnn_class_loss: 0.4853 - val_mrcnn_bbox_loss: 0.2960 - val_mrcnn_mask_loss: 0.3686\n",
      "Epoch 48/120\n",
      "146/146 [==============================] - 529s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4954 - rpn_class_loss: 0.0184 - rpn_bbox_loss: 0.0353 - mrcnn_class_loss: 0.0890 - mrcnn_bbox_loss: 0.0818 - mrcnn_mask_loss: 0.2710 - val_loss: 2.1814 - val_rpn_class_loss: 0.3014 - val_rpn_bbox_loss: 0.7242 - val_mrcnn_class_loss: 0.4942 - val_mrcnn_bbox_loss: 0.3004 - val_mrcnn_mask_loss: 0.3613\n",
      "Epoch 49/120\n",
      "146/146 [==============================] - 541s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.5161 - rpn_class_loss: 0.0183 - rpn_bbox_loss: 0.0392 - mrcnn_class_loss: 0.0884 - mrcnn_bbox_loss: 0.0892 - mrcnn_mask_loss: 0.2810 - val_loss: 2.2644 - val_rpn_class_loss: 0.3109 - val_rpn_bbox_loss: 0.9030 - val_mrcnn_class_loss: 0.3576 - val_mrcnn_bbox_loss: 0.2925 - val_mrcnn_mask_loss: 0.4004\n",
      "Epoch 50/120\n",
      "146/146 [==============================] - 605s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4866 - rpn_class_loss: 0.0174 - rpn_bbox_loss: 0.0413 - mrcnn_class_loss: 0.0743 - mrcnn_bbox_loss: 0.0820 - mrcnn_mask_loss: 0.2717 - val_loss: 2.3053 - val_rpn_class_loss: 0.4231 - val_rpn_bbox_loss: 0.8234 - val_mrcnn_class_loss: 0.4173 - val_mrcnn_bbox_loss: 0.2818 - val_mrcnn_mask_loss: 0.3596\n",
      "Epoch 51/120\n",
      "146/146 [==============================] - 539s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4937 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.0425 - mrcnn_class_loss: 0.0768 - mrcnn_bbox_loss: 0.0845 - mrcnn_mask_loss: 0.2732 - val_loss: 2.1128 - val_rpn_class_loss: 0.2913 - val_rpn_bbox_loss: 0.7656 - val_mrcnn_class_loss: 0.4098 - val_mrcnn_bbox_loss: 0.2892 - val_mrcnn_mask_loss: 0.3568\n",
      "Epoch 52/120\n",
      "146/146 [==============================] - 579s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4765 - rpn_class_loss: 0.0181 - rpn_bbox_loss: 0.0412 - mrcnn_class_loss: 0.0746 - mrcnn_bbox_loss: 0.0772 - mrcnn_mask_loss: 0.2653 - val_loss: 2.2077 - val_rpn_class_loss: 0.3203 - val_rpn_bbox_loss: 0.8789 - val_mrcnn_class_loss: 0.3762 - val_mrcnn_bbox_loss: 0.2786 - val_mrcnn_mask_loss: 0.3537\n",
      "Epoch 53/120\n",
      "146/146 [==============================] - 641s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4619 - rpn_class_loss: 0.0163 - rpn_bbox_loss: 0.0341 - mrcnn_class_loss: 0.0761 - mrcnn_bbox_loss: 0.0753 - mrcnn_mask_loss: 0.2601 - val_loss: 2.4286 - val_rpn_class_loss: 0.4094 - val_rpn_bbox_loss: 0.8189 - val_mrcnn_class_loss: 0.5412 - val_mrcnn_bbox_loss: 0.2956 - val_mrcnn_mask_loss: 0.3634\n",
      "Epoch 54/120\n",
      "146/146 [==============================] - 511s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4654 - rpn_class_loss: 0.0162 - rpn_bbox_loss: 0.0395 - mrcnn_class_loss: 0.0707 - mrcnn_bbox_loss: 0.0750 - mrcnn_mask_loss: 0.2640 - val_loss: 2.1465 - val_rpn_class_loss: 0.2981 - val_rpn_bbox_loss: 0.7815 - val_mrcnn_class_loss: 0.4233 - val_mrcnn_bbox_loss: 0.2899 - val_mrcnn_mask_loss: 0.3538\n",
      "Epoch 55/120\n",
      "146/146 [==============================] - 593s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4580 - rpn_class_loss: 0.0146 - rpn_bbox_loss: 0.0369 - mrcnn_class_loss: 0.0750 - mrcnn_bbox_loss: 0.0714 - mrcnn_mask_loss: 0.2600 - val_loss: 2.1900 - val_rpn_class_loss: 0.3167 - val_rpn_bbox_loss: 0.8410 - val_mrcnn_class_loss: 0.3919 - val_mrcnn_bbox_loss: 0.2775 - val_mrcnn_mask_loss: 0.3629\n",
      "Epoch 56/120\n",
      "146/146 [==============================] - 508s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4398 - rpn_class_loss: 0.0150 - rpn_bbox_loss: 0.0350 - mrcnn_class_loss: 0.0673 - mrcnn_bbox_loss: 0.0693 - mrcnn_mask_loss: 0.2531 - val_loss: 2.1473 - val_rpn_class_loss: 0.3114 - val_rpn_bbox_loss: 0.7593 - val_mrcnn_class_loss: 0.4465 - val_mrcnn_bbox_loss: 0.2785 - val_mrcnn_mask_loss: 0.3518\n",
      "Epoch 57/120\n",
      "146/146 [==============================] - 589s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4471 - rpn_class_loss: 0.0165 - rpn_bbox_loss: 0.0312 - mrcnn_class_loss: 0.0705 - mrcnn_bbox_loss: 0.0713 - mrcnn_mask_loss: 0.2576 - val_loss: 2.3618 - val_rpn_class_loss: 0.3697 - val_rpn_bbox_loss: 0.8319 - val_mrcnn_class_loss: 0.5338 - val_mrcnn_bbox_loss: 0.2776 - val_mrcnn_mask_loss: 0.3488\n",
      "Epoch 58/120\n",
      "146/146 [==============================] - 622s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4313 - rpn_class_loss: 0.0148 - rpn_bbox_loss: 0.0295 - mrcnn_class_loss: 0.0647 - mrcnn_bbox_loss: 0.0685 - mrcnn_mask_loss: 0.2538 - val_loss: 2.2329 - val_rpn_class_loss: 0.3536 - val_rpn_bbox_loss: 0.8177 - val_mrcnn_class_loss: 0.4123 - val_mrcnn_bbox_loss: 0.2807 - val_mrcnn_mask_loss: 0.3687\n",
      "Epoch 59/120\n",
      "146/146 [==============================] - 559s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4478 - rpn_class_loss: 0.0148 - rpn_bbox_loss: 0.0384 - mrcnn_class_loss: 0.0643 - mrcnn_bbox_loss: 0.0721 - mrcnn_mask_loss: 0.2583 - val_loss: 2.3103 - val_rpn_class_loss: 0.4185 - val_rpn_bbox_loss: 0.8036 - val_mrcnn_class_loss: 0.4664 - val_mrcnn_bbox_loss: 0.2723 - val_mrcnn_mask_loss: 0.3495\n",
      "Epoch 60/120\n",
      "146/146 [==============================] - 560s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4240 - rpn_class_loss: 0.0151 - rpn_bbox_loss: 0.0327 - mrcnn_class_loss: 0.0642 - mrcnn_bbox_loss: 0.0653 - mrcnn_mask_loss: 0.2468 - val_loss: 2.2724 - val_rpn_class_loss: 0.3460 - val_rpn_bbox_loss: 0.8470 - val_mrcnn_class_loss: 0.4531 - val_mrcnn_bbox_loss: 0.2681 - val_mrcnn_mask_loss: 0.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "146/146 [==============================] - 657s 5s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4357 - rpn_class_loss: 0.0139 - rpn_bbox_loss: 0.0328 - mrcnn_class_loss: 0.0649 - mrcnn_bbox_loss: 0.0679 - mrcnn_mask_loss: 0.2563 - val_loss: 2.1679 - val_rpn_class_loss: 0.3364 - val_rpn_bbox_loss: 0.8242 - val_mrcnn_class_loss: 0.3821 - val_mrcnn_bbox_loss: 0.2778 - val_mrcnn_mask_loss: 0.3475\n",
      "Epoch 62/120\n",
      "146/146 [==============================] - 574s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4437 - rpn_class_loss: 0.0141 - rpn_bbox_loss: 0.0388 - mrcnn_class_loss: 0.0659 - mrcnn_bbox_loss: 0.0720 - mrcnn_mask_loss: 0.2529 - val_loss: 2.1375 - val_rpn_class_loss: 0.3106 - val_rpn_bbox_loss: 0.7752 - val_mrcnn_class_loss: 0.4304 - val_mrcnn_bbox_loss: 0.2750 - val_mrcnn_mask_loss: 0.3464\n",
      "Epoch 63/120\n",
      "146/146 [==============================] - 572s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.4124 - rpn_class_loss: 0.0133 - rpn_bbox_loss: 0.0308 - mrcnn_class_loss: 0.0597 - mrcnn_bbox_loss: 0.0637 - mrcnn_mask_loss: 0.2449 - val_loss: 2.1409 - val_rpn_class_loss: 0.3053 - val_rpn_bbox_loss: 0.7842 - val_mrcnn_class_loss: 0.4143 - val_mrcnn_bbox_loss: 0.2750 - val_mrcnn_mask_loss: 0.3621\n",
      "Epoch 64/120\n",
      "146/146 [==============================] - 668s 5s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3923 - rpn_class_loss: 0.0121 - rpn_bbox_loss: 0.0320 - mrcnn_class_loss: 0.0526 - mrcnn_bbox_loss: 0.0570 - mrcnn_mask_loss: 0.2387 - val_loss: 2.2511 - val_rpn_class_loss: 0.3835 - val_rpn_bbox_loss: 0.7283 - val_mrcnn_class_loss: 0.5084 - val_mrcnn_bbox_loss: 0.2795 - val_mrcnn_mask_loss: 0.3513\n",
      "Epoch 65/120\n",
      "146/146 [==============================] - 584s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3952 - rpn_class_loss: 0.0123 - rpn_bbox_loss: 0.0288 - mrcnn_class_loss: 0.0532 - mrcnn_bbox_loss: 0.0581 - mrcnn_mask_loss: 0.2429 - val_loss: 2.4777 - val_rpn_class_loss: 0.4673 - val_rpn_bbox_loss: 0.9059 - val_mrcnn_class_loss: 0.4745 - val_mrcnn_bbox_loss: 0.2796 - val_mrcnn_mask_loss: 0.3504\n",
      "Epoch 66/120\n",
      "146/146 [==============================] - 603s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3896 - rpn_class_loss: 0.0121 - rpn_bbox_loss: 0.0281 - mrcnn_class_loss: 0.0552 - mrcnn_bbox_loss: 0.0572 - mrcnn_mask_loss: 0.2369 - val_loss: 2.3477 - val_rpn_class_loss: 0.3750 - val_rpn_bbox_loss: 0.8324 - val_mrcnn_class_loss: 0.4960 - val_mrcnn_bbox_loss: 0.2855 - val_mrcnn_mask_loss: 0.3588\n",
      "Epoch 67/120\n",
      "146/146 [==============================] - 499s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3739 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.0257 - mrcnn_class_loss: 0.0485 - mrcnn_bbox_loss: 0.0551 - mrcnn_mask_loss: 0.2322 - val_loss: 2.1561 - val_rpn_class_loss: 0.3178 - val_rpn_bbox_loss: 0.7806 - val_mrcnn_class_loss: 0.4246 - val_mrcnn_bbox_loss: 0.2800 - val_mrcnn_mask_loss: 0.3531\n",
      "Epoch 68/120\n",
      "146/146 [==============================] - 547s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3952 - rpn_class_loss: 0.0112 - rpn_bbox_loss: 0.0316 - mrcnn_class_loss: 0.0538 - mrcnn_bbox_loss: 0.0598 - mrcnn_mask_loss: 0.2387 - val_loss: 2.3255 - val_rpn_class_loss: 0.3869 - val_rpn_bbox_loss: 0.9319 - val_mrcnn_class_loss: 0.3834 - val_mrcnn_bbox_loss: 0.2667 - val_mrcnn_mask_loss: 0.3566\n",
      "Epoch 69/120\n",
      "146/146 [==============================] - 624s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3862 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.0302 - mrcnn_class_loss: 0.0550 - mrcnn_bbox_loss: 0.0576 - mrcnn_mask_loss: 0.2310 - val_loss: 2.3276 - val_rpn_class_loss: 0.3723 - val_rpn_bbox_loss: 0.7863 - val_mrcnn_class_loss: 0.5127 - val_mrcnn_bbox_loss: 0.2846 - val_mrcnn_mask_loss: 0.3715\n",
      "Epoch 70/120\n",
      "146/146 [==============================] - 532s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3821 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.0297 - mrcnn_class_loss: 0.0504 - mrcnn_bbox_loss: 0.0584 - mrcnn_mask_loss: 0.2318 - val_loss: 2.3645 - val_rpn_class_loss: 0.4009 - val_rpn_bbox_loss: 0.8975 - val_mrcnn_class_loss: 0.4523 - val_mrcnn_bbox_loss: 0.2619 - val_mrcnn_mask_loss: 0.3520\n",
      "Epoch 71/120\n",
      "146/146 [==============================] - 559s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3775 - rpn_class_loss: 0.0115 - rpn_bbox_loss: 0.0275 - mrcnn_class_loss: 0.0537 - mrcnn_bbox_loss: 0.0565 - mrcnn_mask_loss: 0.2284 - val_loss: 2.3762 - val_rpn_class_loss: 0.4085 - val_rpn_bbox_loss: 0.8650 - val_mrcnn_class_loss: 0.4708 - val_mrcnn_bbox_loss: 0.2748 - val_mrcnn_mask_loss: 0.3571\n",
      "Epoch 72/120\n",
      "146/146 [==============================] - 588s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3504 - rpn_class_loss: 0.0111 - rpn_bbox_loss: 0.0255 - mrcnn_class_loss: 0.0444 - mrcnn_bbox_loss: 0.0492 - mrcnn_mask_loss: 0.2202 - val_loss: 2.4755 - val_rpn_class_loss: 0.4406 - val_rpn_bbox_loss: 0.8395 - val_mrcnn_class_loss: 0.5536 - val_mrcnn_bbox_loss: 0.2692 - val_mrcnn_mask_loss: 0.3727\n",
      "Epoch 73/120\n",
      "146/146 [==============================] - 484s 3s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3624 - rpn_class_loss: 0.0117 - rpn_bbox_loss: 0.0265 - mrcnn_class_loss: 0.0481 - mrcnn_bbox_loss: 0.0528 - mrcnn_mask_loss: 0.2232 - val_loss: 2.1751 - val_rpn_class_loss: 0.3127 - val_rpn_bbox_loss: 0.7608 - val_mrcnn_class_loss: 0.4690 - val_mrcnn_bbox_loss: 0.2783 - val_mrcnn_mask_loss: 0.3542\n",
      "Epoch 74/120\n",
      "146/146 [==============================] - 555s 4s/step - batch: 72.5000 - size: 2.0000 - loss: 0.3551 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.0254 - mrcnn_class_loss: 0.0484 - mrcnn_bbox_loss: 0.0496 - mrcnn_mask_loss: 0.2205 - val_loss: 2.3834 - val_rpn_class_loss: 0.3808 - val_rpn_bbox_loss: 0.8081 - val_mrcnn_class_loss: 0.5249 - val_mrcnn_bbox_loss: 0.2746 - val_mrcnn_mask_loss: 0.3950\n",
      "Epoch 75/120\n",
      " 40/146 [=======>......................] - ETA: 2:59 - batch: 19.5000 - size: 2.0000 - loss: 0.3370 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.0218 - mrcnn_class_loss: 0.0386 - mrcnn_bbox_loss: 0.0515 - mrcnn_mask_loss: 0.2152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f8801700709f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# you can change epochs and layers (head or all)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=100, layers='all', augmentation=augmentation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/PT_JoseVeloso/Mask_RCNN-master_matterport/model-training/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2355\u001b[0m             \u001b[0;31m#workers = 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m         self.keras_model.fit(\n\u001b[0m\u001b[1;32m   2358\u001b[0m             \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         return func.fit(\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         )\n\u001b[0;32m--> 648\u001b[0;31m         return fit_generator(\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cargar dataset de entrenamiento\n",
    "train_set = DatasetArandanos()\n",
    "train_set.load_dataset(conjunto_datos, is_train=True)\n",
    "train_set.prepare()\n",
    "\n",
    "# cargar dataset de test \n",
    "test_set = DatasetArandanos()\n",
    "test_set.load_dataset(conjunto_datos, is_train=False)\n",
    "test_set.prepare()\n",
    "\n",
    "# preparar la configuración llamando a la clase de configuración definida por el usuario\n",
    "config = ConfigArandanos()\n",
    "\n",
    "# definir el modelo\n",
    "with tf.device(config.DEVICE):\n",
    "    model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "\n",
    "# cargar pesos del modelo \n",
    "weights_path = pesos\n",
    "\n",
    "# cargar los pesos del modelo\n",
    "model.load_weights(weights_path, \n",
    "                   by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# start the training of model\n",
    "# you can change epochs and layers (head or all)\n",
    "#model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=100, layers='all', augmentation=augmentation)\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=120, layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "master.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "da38062997892a68ae88df3a1549a85ff68f4e3a875c1f51aead31b07f2af4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
