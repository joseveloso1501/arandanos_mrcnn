{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 11 (paper) - Experimento 7 (PT)\n",
    "\n",
    "Entrenamiento de Mask R-CNN con dataset modificado para emular \"Test 11\"\n",
    "\n",
    "### Hiperparametros\n",
    "* **epoch = 100**\n",
    "    * steps x epoch = 146 (lotes de imagenes)\n",
    "    * batch = 2\n",
    "* optimizador = SGD\n",
    "* Funcion de perdida = SMOOTHL1LOSS\n",
    "* Metrica de evaluacion = mAP (IoU >= 0.5)\n",
    "* **Mini-mask shape: 28x28**\n",
    "* **RPN anchor scales: (8, 16, 32, 64, 128)**\n",
    "* Tasa de aprendizaje: 0.001\n",
    "* **imagenes = 305**\n",
    "    * entrenamiento 70% = 177\n",
    "    * validacion 30% = 128\n",
    "* etiquetas = 9140\n",
    "* **resolucion = 1920 x 1080**\n",
    "* etiquetas = bounding box formato VOC XML\n",
    "* **numero de clases = 2 (arandano, arandano-maduro)**\n",
    "* **data augmentation = false**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9csYdOiCeux-"
   },
   "source": [
    "## Comprobar directorio principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/PT_JoseVeloso/Mask_RCNN-master_matterport/model-training\r\n",
      "total 1536\r\n",
      "drwxr-xr-x 4 root root   4096 Aug  7 06:10 build\r\n",
      "drwxr-xr-x 2 root root   4096 Aug  7 06:10 dist\r\n",
      "drwxr-xr-x 2 root root   4096 Aug  8 03:15 mask_rcnn.egg-info\r\n",
      "-rw-r--r-- 1 root root  25109 Sep 16 03:35 master-test_11_fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 350337 Sep 15 00:38 master-test_5-fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 162975 Sep 15 02:26 master-test_5-fine_tuning_1.ipynb\r\n",
      "-rw-r--r-- 1 root root 162983 Sep 15 02:23 master-test_5.ipynb\r\n",
      "-rw-r--r-- 1 root root 350111 Sep 15 02:26 master-test_5_fase_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 110478 Sep 15 02:15 master-test_6-fine_tuning_1.ipynb\r\n",
      "-rw-r--r-- 1 root root 110254 Sep 15 02:25 master-test_6.ipynb\r\n",
      "-rw-r--r-- 1 root root 270148 Sep 15 15:04 master-test_6_fase_2.ipynb\r\n",
      "drwxr-xr-x 4 root root   4096 Sep 13 07:49 mrcnn\r\n",
      "drwxr-xr-x 3 root root   4096 Sep 15 02:27 old\r\n"
     ]
    }
   ],
   "source": [
    "!pwd && ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6qajN7v0saE"
   },
   "source": [
    "# Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6812,
     "status": "ok",
     "timestamp": 1659596011947,
     "user": {
      "displayName": "José Ignacio Veloso Inzunza",
      "userId": "04140603416196179882"
     },
     "user_tz": 240
    },
    "id": "iyA_0ghC0saJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bibliotecas basicas\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "#sys.path.append(\"/tf/PT_JoseVeloso/Mask_RCNN-master/\")\n",
    "\n",
    "# bibliotecas avanzadas \n",
    "from xml.etree import ElementTree\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import imgaug\n",
    "\n",
    "# bibliotecas mask rcnn \n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn import visualize\n",
    "\n",
    "# biblioteca matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# bibliotecas numpy \n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "\n",
    "# bibliotecas keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img   #keras.preprocessing.image tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# ignorar alertas de elementos que seran descontinuados\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "%matplotlib inline\n",
    "#plt.show()\n",
    "\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Mbj3-t70saL"
   },
   "source": [
    "# Fase 2 - Entrenamiento con dos clases y etiquetas de Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGtz-ovS0saM"
   },
   "source": [
    "En este entremamiento se utiliza un conjunto de datos simple con imágenes etiquetadas con cuadros delimitadores y una clase llamada 'Daño'. En la siguiente sección se encuentra el código para el entrenamiento del modelo. Se incluyen comentarios para describir mejor el flujo del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetArandanos(Dataset):\n",
    "    \n",
    "    # load_dataset function is used to load the train and test dataset\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        \n",
    "        # we use add_class for each class in our dataset and assign numbers to them. 0 is background\n",
    "        # self.add_class('source', 'class id', 'class name')\n",
    "        self.add_class(\"dataset\", 1, \"arandano\")\n",
    "        self.add_class(\"dataset\", 2, \"arandano-maduro\")\n",
    "        #self.add_class(\"dataset\", 3, \"Level-3\")\n",
    "        #self.add_class(\"dataset\", 4, \"Level-4\")\n",
    "        \n",
    "        # we concatenate the dataset_dir with /images and /annots\n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annots/'\n",
    "        \n",
    "        # is_train will be true if we our training our model and false when we are testing the model\n",
    "        for filename in listdir(images_dir):\n",
    "            \n",
    "            # extract image id\n",
    "            image_id = filename[:-4] # used to skip last 4 chars which is '.jpg' (class_id.jpg)\n",
    "            \n",
    "            # if is_train is True skip all images with id greater than and equal to 160\n",
    "             # roughly 80% of dataset for training\n",
    "            if is_train and int(image_id) >= 11074 :\n",
    "                #print(\"image_id: \", image_id)\n",
    "                continue\n",
    "             \n",
    "            # if is_train is not True skip all images with id less than 420\n",
    "            if not is_train and int(image_id) < 11074:\n",
    "                continue\n",
    "            \n",
    "            # img_path and ann_path variables are defined\n",
    "            img_path = images_dir + filename\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            \n",
    "            # using add_image function we pass image_id, image_path and ann_path so that the current\n",
    "            # image is added to the dataset for training\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "    # function used to extract bouding boxes from annotated files\n",
    "    def extract_boxes(self, filename):\n",
    "\n",
    "        # you can see how the images are annotated we extracrt the width, height and bndbox values\n",
    "\n",
    "        # <size>\n",
    "\n",
    "        #       <width>640</width>\n",
    "\n",
    "        #       <height>360</height>\n",
    "\n",
    "        #       <depth>3</depth>\n",
    "\n",
    "        # </size>\n",
    "\n",
    "\n",
    "        # <object>\n",
    "\n",
    "        #          <name>damage</name>\n",
    "\n",
    "        #          <pose>Unspecified</pose>\n",
    "\n",
    "        #          <truncated>0</truncated>\n",
    "\n",
    "        #          <difficult>0</difficult>\n",
    "\n",
    "\n",
    "        #          <bndbox>\n",
    "\n",
    "        #                 <xmin>315</xmin>\n",
    "\n",
    "        #                 <ymin>160</ymin>\n",
    "\n",
    "        #                 <xmax>381</xmax>\n",
    "\n",
    "        #                 <ymax>199</ymax>\n",
    "\n",
    "        #          </bndbox>\n",
    "\n",
    "        # </object>\n",
    "\n",
    "        # </annotation>\n",
    "        \n",
    "        # used to parse the .xml files\n",
    "        tree = ElementTree.parse(filename)\n",
    "        \n",
    "        # to get the root of the xml file\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # we will append all x, y coordinated in boxes\n",
    "        # for all instances of an onject\n",
    "        boxes = list()\n",
    "        \n",
    "        # we find all attributes with name bndbox\n",
    "        # bndbox will exist for each ground truth in an image\n",
    "        for box in root.findall('.//object'):\n",
    "            name = box.find('name').text\n",
    "            xmin = int(box.find('./bndbox/xmin').text)\n",
    "            ymin = int(box.find('./bndbox/ymin').text)\n",
    "            xmax = int(box.find('./bndbox/xmax').text)\n",
    "            ymax = int(box.find('./bndbox/ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax, name]\n",
    "            boxes.append(coors)\n",
    "            \n",
    "            # I have included this line to skip any un-annotated images\n",
    "            if name=='arandano' or name=='arandano-maduro':\n",
    "                boxes.append(coors)\n",
    "\n",
    "        # extract width and height of the image\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        \n",
    "        # return boxes-> list, width-> int and height-> int \n",
    "        return boxes, width, height\n",
    "    \n",
    "    # this function calls on the extract_boxes method and is used to load a mask for each instance in an image\n",
    "    # returns a boolean mask with following dimensions width * height * instances        \n",
    "    def load_mask(self, image_id):\n",
    "        \n",
    "        # info points to the current image_id\n",
    "        info = self.image_info[image_id]\n",
    "        \n",
    "        # we get the annotation path of image_id which is dataset_dir/annots/image_id.xml\n",
    "        path = info['annotation']\n",
    "        \n",
    "        # we call the extract_boxes method(above) to get bndbox from .xml file\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        \n",
    "        # we create len(boxes) number of masks of height 'h' and width 'w'\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\n",
    "        class_ids = list()\n",
    "        \n",
    "        # we loop over all boxes and generate masks (bndbox mask) and class id for each instance\n",
    "        # masks will have rectange shape as we have used bndboxes for annotations\n",
    "        # for example: if 2.jpg have four objects we will have following masks and class_ids\n",
    "        # 000000000 000000000 000003330 111100000\n",
    "        # 000011100 022200000 000003330 111100000\n",
    "        # 000011100 022200000 000003330 111100000\n",
    "        # 000000000 022200000 000000000 000000000\n",
    "        #    1         2          3         1<- class_ids\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            \n",
    "            # box[4] will have the name of the class for a particular damage\n",
    "            if (box[4] == 'arandano'):\n",
    "                masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "                class_ids.append(self.class_names.index('arandano'))\n",
    "            elif(box[4] == 'arandano-maduro'):\n",
    "                masks[row_s:row_e, col_s:col_e, i] = 2\n",
    "                class_ids.append(self.class_names.index('arandano-maduro')) \n",
    "                \n",
    "        # return masks and class_ids as array\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "    \n",
    "    # this functions takes the image_id and returns the path of the image\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DEVICE                         /gpu:0\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.8\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (28, 28)\n",
      "NAME                           arandano_cfg_test_11_fase_2_\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 1.5]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                61\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "Train_ROIs_Per_Image           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# damage configuration class, you can change values of hyper parameters here\n",
    "class ConfigArandanos(Config):\n",
    "\n",
    "    # nombre de la configuracion\n",
    "    NAME = \"arandano_cfg_test_11_fase_2_\"    \n",
    "    \n",
    "    # clase arandano + clase background + 4 clases\n",
    "    NUM_CLASSES = 1 + 2\n",
    "    \n",
    "    # pasos por epoch y confianza minima    # STEPS_PER_EPOCH = cantidad de lotes/batchs\n",
    "    STEPS_PER_EPOCH = 61  # por epoch se entrenaran 61 lotes de 5 imagenes, dataset = 305\n",
    "\n",
    "    # tasa de aprendizaje y momentum\n",
    "    LEARNING_RATE=0.001\n",
    "    LEARNING_MOMENTUM = 0.8\n",
    "    \n",
    "    # penalización de regularización\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    \n",
    "    # el tamaño de la imagen está controlado por este parámetro\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    \n",
    "    # pasos de validación\n",
    "    VALIDATION_STEPS = 50\n",
    "    \n",
    "    # número de regiones de interés generadas por imagen\n",
    "    Train_ROIs_Per_Image = 200\n",
    "    \n",
    "    # escala de anclas RPN y proporciones (ratios) para encontrar la ROI\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)    # Longitud del lado del ancla cuadrada, en píxeles \n",
    "    RPN_ANCHOR_RATIOS = [0.5, 1, 1.5]   # Proporciones de anclas por cada celda (ancho/alto). Un valor de 1 representa un ancla cuadrada y 0,5 es un ancla ancha \n",
    "\n",
    "    #DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0    \n",
    "    DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "    MINI_MASK_SHAPE = (28, 28)\n",
    "    \n",
    "ConfigArandanos().display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/PT_JoseVeloso/Mask_RCNN-master_matterport\n"
     ]
    }
   ],
   "source": [
    "cd /tf/PT_JoseVeloso/Mask_RCNN-master_matterport/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pesos = 'mask_rcnn_coco.h5'\n",
    "#pesos = 'mask_rcnn_damage_cfg_0049.h5'\n",
    "#pesos = 'arandano_cfg_test_5_20220907T0914/mask_rcnn_arandano_cfg_0300.h5'\n",
    "#pesos = 'arandano_cfg_test_5_20220907T0914/mask_rcnn_arandano_cfg_0300.h5'\n",
    "pesos = 'arandano_cfg_test_6_fase_2_20220915T0216/mask_rcnn_arandano_cfg_test_6_fase_2__0100.h5'\n",
    "\n",
    "conjunto_datos = 'customImages/test_11_fase_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3787125,
     "status": "ok",
     "timestamp": 1659604139130,
     "user": {
      "displayName": "José Ignacio Veloso Inzunza",
      "userId": "04140603416196179882"
     },
     "user_tz": 240
    },
    "id": "dF77APDH0saM",
    "outputId": "aa2a0330-e201-4b00-b12c-fee7986449cb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./arandano_cfg_test_11_fase_2_20220916T0336/mask_rcnn_arandano_cfg_test_11_fase_2__{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (AnchorsLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32, device=/device:GPU:0))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32, device=/device:GPU:0))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 383s 6s/step - batch: 30.0000 - size: 2.0000 - loss: 4.5276 - rpn_class_loss: 0.3208 - rpn_bbox_loss: 2.1583 - mrcnn_class_loss: 0.0973 - mrcnn_bbox_loss: 1.3937 - mrcnn_mask_loss: 0.5574 - val_loss: 2.5070 - val_rpn_class_loss: 0.2687 - val_rpn_bbox_loss: 0.8192 - val_mrcnn_class_loss: 0.1705 - val_mrcnn_bbox_loss: 0.7376 - val_mrcnn_mask_loss: 0.5110\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 293s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.8865 - rpn_class_loss: 0.0953 - rpn_bbox_loss: 0.6682 - mrcnn_class_loss: 0.0834 - mrcnn_bbox_loss: 0.5546 - mrcnn_mask_loss: 0.4850 - val_loss: 2.1111 - val_rpn_class_loss: 0.1831 - val_rpn_bbox_loss: 0.7234 - val_mrcnn_class_loss: 0.1726 - val_mrcnn_bbox_loss: 0.5394 - val_mrcnn_mask_loss: 0.4925\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 267s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 1.6548 - rpn_class_loss: 0.0845 - rpn_bbox_loss: 0.5630 - mrcnn_class_loss: 0.1614 - mrcnn_bbox_loss: 0.3892 - mrcnn_mask_loss: 0.4566 - val_loss: 2.0418 - val_rpn_class_loss: 0.1595 - val_rpn_bbox_loss: 0.7319 - val_mrcnn_class_loss: 0.1678 - val_mrcnn_bbox_loss: 0.5496 - val_mrcnn_mask_loss: 0.4330\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 297s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.5366 - rpn_class_loss: 0.0655 - rpn_bbox_loss: 0.4776 - mrcnn_class_loss: 0.2167 - mrcnn_bbox_loss: 0.3321 - mrcnn_mask_loss: 0.4446 - val_loss: 2.1349 - val_rpn_class_loss: 0.1445 - val_rpn_bbox_loss: 0.7267 - val_mrcnn_class_loss: 0.2439 - val_mrcnn_bbox_loss: 0.5495 - val_mrcnn_mask_loss: 0.4703\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 271s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.3845 - rpn_class_loss: 0.0506 - rpn_bbox_loss: 0.3925 - mrcnn_class_loss: 0.2188 - mrcnn_bbox_loss: 0.2945 - mrcnn_mask_loss: 0.4282 - val_loss: 2.1230 - val_rpn_class_loss: 0.1534 - val_rpn_bbox_loss: 0.7288 - val_mrcnn_class_loss: 0.2510 - val_mrcnn_bbox_loss: 0.5268 - val_mrcnn_mask_loss: 0.4629\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 280s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.2769 - rpn_class_loss: 0.0484 - rpn_bbox_loss: 0.3212 - mrcnn_class_loss: 0.2117 - mrcnn_bbox_loss: 0.2656 - mrcnn_mask_loss: 0.4300 - val_loss: 2.0782 - val_rpn_class_loss: 0.1430 - val_rpn_bbox_loss: 0.7224 - val_mrcnn_class_loss: 0.2376 - val_mrcnn_bbox_loss: 0.5240 - val_mrcnn_mask_loss: 0.4511\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 294s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.2032 - rpn_class_loss: 0.0445 - rpn_bbox_loss: 0.2858 - mrcnn_class_loss: 0.2010 - mrcnn_bbox_loss: 0.2580 - mrcnn_mask_loss: 0.4138 - val_loss: 2.1394 - val_rpn_class_loss: 0.1955 - val_rpn_bbox_loss: 0.7229 - val_mrcnn_class_loss: 0.2569 - val_mrcnn_bbox_loss: 0.5215 - val_mrcnn_mask_loss: 0.4426\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 293s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.1695 - rpn_class_loss: 0.0462 - rpn_bbox_loss: 0.2460 - mrcnn_class_loss: 0.2046 - mrcnn_bbox_loss: 0.2568 - mrcnn_mask_loss: 0.4159 - val_loss: 2.1307 - val_rpn_class_loss: 0.1572 - val_rpn_bbox_loss: 0.7501 - val_mrcnn_class_loss: 0.2957 - val_mrcnn_bbox_loss: 0.4962 - val_mrcnn_mask_loss: 0.4315\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 298s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 1.0409 - rpn_class_loss: 0.0341 - rpn_bbox_loss: 0.1725 - mrcnn_class_loss: 0.2055 - mrcnn_bbox_loss: 0.2210 - mrcnn_mask_loss: 0.4078 - val_loss: 2.1284 - val_rpn_class_loss: 0.1787 - val_rpn_bbox_loss: 0.7221 - val_mrcnn_class_loss: 0.2966 - val_mrcnn_bbox_loss: 0.4890 - val_mrcnn_mask_loss: 0.4420\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 340s 6s/step - batch: 30.0000 - size: 2.0000 - loss: 0.9784 - rpn_class_loss: 0.0351 - rpn_bbox_loss: 0.1542 - mrcnn_class_loss: 0.1841 - mrcnn_bbox_loss: 0.2044 - mrcnn_mask_loss: 0.4005 - val_loss: 2.1269 - val_rpn_class_loss: 0.1605 - val_rpn_bbox_loss: 0.6929 - val_mrcnn_class_loss: 0.3627 - val_mrcnn_bbox_loss: 0.4818 - val_mrcnn_mask_loss: 0.4290\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 338s 6s/step - batch: 30.0000 - size: 2.0000 - loss: 0.8911 - rpn_class_loss: 0.0284 - rpn_bbox_loss: 0.1104 - mrcnn_class_loss: 0.1664 - mrcnn_bbox_loss: 0.1911 - mrcnn_mask_loss: 0.3948 - val_loss: 2.3902 - val_rpn_class_loss: 0.2697 - val_rpn_bbox_loss: 0.7433 - val_mrcnn_class_loss: 0.4387 - val_mrcnn_bbox_loss: 0.4966 - val_mrcnn_mask_loss: 0.4419\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 288s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.8971 - rpn_class_loss: 0.0307 - rpn_bbox_loss: 0.1146 - mrcnn_class_loss: 0.1667 - mrcnn_bbox_loss: 0.1907 - mrcnn_mask_loss: 0.3943 - val_loss: 2.2697 - val_rpn_class_loss: 0.2408 - val_rpn_bbox_loss: 0.7587 - val_mrcnn_class_loss: 0.3441 - val_mrcnn_bbox_loss: 0.4919 - val_mrcnn_mask_loss: 0.4342\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 314s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.8773 - rpn_class_loss: 0.0379 - rpn_bbox_loss: 0.1053 - mrcnn_class_loss: 0.1656 - mrcnn_bbox_loss: 0.1822 - mrcnn_mask_loss: 0.3862 - val_loss: 2.3075 - val_rpn_class_loss: 0.2268 - val_rpn_bbox_loss: 0.7328 - val_mrcnn_class_loss: 0.3952 - val_mrcnn_bbox_loss: 0.5152 - val_mrcnn_mask_loss: 0.4376\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 337s 6s/step - batch: 30.0000 - size: 2.0000 - loss: 0.8218 - rpn_class_loss: 0.0323 - rpn_bbox_loss: 0.0838 - mrcnn_class_loss: 0.1613 - mrcnn_bbox_loss: 0.1657 - mrcnn_mask_loss: 0.3787 - val_loss: 2.4813 - val_rpn_class_loss: 0.3270 - val_rpn_bbox_loss: 0.7968 - val_mrcnn_class_loss: 0.4182 - val_mrcnn_bbox_loss: 0.4918 - val_mrcnn_mask_loss: 0.4475\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 289s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.8246 - rpn_class_loss: 0.0300 - rpn_bbox_loss: 0.0866 - mrcnn_class_loss: 0.1625 - mrcnn_bbox_loss: 0.1662 - mrcnn_mask_loss: 0.3792 - val_loss: 2.0981 - val_rpn_class_loss: 0.1860 - val_rpn_bbox_loss: 0.6915 - val_mrcnn_class_loss: 0.3490 - val_mrcnn_bbox_loss: 0.4544 - val_mrcnn_mask_loss: 0.4171\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 307s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.7460 - rpn_class_loss: 0.0306 - rpn_bbox_loss: 0.0618 - mrcnn_class_loss: 0.1403 - mrcnn_bbox_loss: 0.1390 - mrcnn_mask_loss: 0.3743 - val_loss: 2.1469 - val_rpn_class_loss: 0.1719 - val_rpn_bbox_loss: 0.7212 - val_mrcnn_class_loss: 0.3450 - val_mrcnn_bbox_loss: 0.4792 - val_mrcnn_mask_loss: 0.4297\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 262s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.7444 - rpn_class_loss: 0.0249 - rpn_bbox_loss: 0.0625 - mrcnn_class_loss: 0.1405 - mrcnn_bbox_loss: 0.1432 - mrcnn_mask_loss: 0.3733 - val_loss: 2.1742 - val_rpn_class_loss: 0.1837 - val_rpn_bbox_loss: 0.7248 - val_mrcnn_class_loss: 0.3744 - val_mrcnn_bbox_loss: 0.4793 - val_mrcnn_mask_loss: 0.4119\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 329s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.7414 - rpn_class_loss: 0.0286 - rpn_bbox_loss: 0.0564 - mrcnn_class_loss: 0.1410 - mrcnn_bbox_loss: 0.1394 - mrcnn_mask_loss: 0.3759 - val_loss: 2.2799 - val_rpn_class_loss: 0.1940 - val_rpn_bbox_loss: 0.7455 - val_mrcnn_class_loss: 0.4329 - val_mrcnn_bbox_loss: 0.4869 - val_mrcnn_mask_loss: 0.4206\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 283s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.7069 - rpn_class_loss: 0.0232 - rpn_bbox_loss: 0.0535 - mrcnn_class_loss: 0.1342 - mrcnn_bbox_loss: 0.1305 - mrcnn_mask_loss: 0.3655 - val_loss: 2.3926 - val_rpn_class_loss: 0.2100 - val_rpn_bbox_loss: 0.7566 - val_mrcnn_class_loss: 0.5331 - val_mrcnn_bbox_loss: 0.4730 - val_mrcnn_mask_loss: 0.4199\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 243s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.7076 - rpn_class_loss: 0.0257 - rpn_bbox_loss: 0.0526 - mrcnn_class_loss: 0.1295 - mrcnn_bbox_loss: 0.1312 - mrcnn_mask_loss: 0.3685 - val_loss: 2.3302 - val_rpn_class_loss: 0.2119 - val_rpn_bbox_loss: 0.7396 - val_mrcnn_class_loss: 0.4513 - val_mrcnn_bbox_loss: 0.4693 - val_mrcnn_mask_loss: 0.4580\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 317s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6758 - rpn_class_loss: 0.0225 - rpn_bbox_loss: 0.0433 - mrcnn_class_loss: 0.1233 - mrcnn_bbox_loss: 0.1268 - mrcnn_mask_loss: 0.3600 - val_loss: 2.2838 - val_rpn_class_loss: 0.2294 - val_rpn_bbox_loss: 0.7579 - val_mrcnn_class_loss: 0.4205 - val_mrcnn_bbox_loss: 0.4520 - val_mrcnn_mask_loss: 0.4239\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 265s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6544 - rpn_class_loss: 0.0227 - rpn_bbox_loss: 0.0422 - mrcnn_class_loss: 0.1200 - mrcnn_bbox_loss: 0.1146 - mrcnn_mask_loss: 0.3549 - val_loss: 2.2139 - val_rpn_class_loss: 0.1313 - val_rpn_bbox_loss: 0.6902 - val_mrcnn_class_loss: 0.4830 - val_mrcnn_bbox_loss: 0.4741 - val_mrcnn_mask_loss: 0.4354\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 282s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6423 - rpn_class_loss: 0.0211 - rpn_bbox_loss: 0.0382 - mrcnn_class_loss: 0.1118 - mrcnn_bbox_loss: 0.1112 - mrcnn_mask_loss: 0.3600 - val_loss: 2.1522 - val_rpn_class_loss: 0.1836 - val_rpn_bbox_loss: 0.7222 - val_mrcnn_class_loss: 0.3976 - val_mrcnn_bbox_loss: 0.4393 - val_mrcnn_mask_loss: 0.4095\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 304s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6395 - rpn_class_loss: 0.0224 - rpn_bbox_loss: 0.0430 - mrcnn_class_loss: 0.1091 - mrcnn_bbox_loss: 0.1102 - mrcnn_mask_loss: 0.3548 - val_loss: 2.2270 - val_rpn_class_loss: 0.1910 - val_rpn_bbox_loss: 0.7055 - val_mrcnn_class_loss: 0.4532 - val_mrcnn_bbox_loss: 0.4540 - val_mrcnn_mask_loss: 0.4233\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 300s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6555 - rpn_class_loss: 0.0198 - rpn_bbox_loss: 0.0530 - mrcnn_class_loss: 0.0993 - mrcnn_bbox_loss: 0.1250 - mrcnn_mask_loss: 0.3583 - val_loss: 2.4707 - val_rpn_class_loss: 0.2038 - val_rpn_bbox_loss: 0.7402 - val_mrcnn_class_loss: 0.4890 - val_mrcnn_bbox_loss: 0.5121 - val_mrcnn_mask_loss: 0.5256\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 274s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6136 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.0392 - mrcnn_class_loss: 0.1009 - mrcnn_bbox_loss: 0.1042 - mrcnn_mask_loss: 0.3491 - val_loss: 2.1876 - val_rpn_class_loss: 0.1864 - val_rpn_bbox_loss: 0.6846 - val_mrcnn_class_loss: 0.4472 - val_mrcnn_bbox_loss: 0.4590 - val_mrcnn_mask_loss: 0.4103\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 244s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.6095 - rpn_class_loss: 0.0201 - rpn_bbox_loss: 0.0425 - mrcnn_class_loss: 0.0965 - mrcnn_bbox_loss: 0.1043 - mrcnn_mask_loss: 0.3461 - val_loss: 2.3768 - val_rpn_class_loss: 0.1931 - val_rpn_bbox_loss: 0.7185 - val_mrcnn_class_loss: 0.5724 - val_mrcnn_bbox_loss: 0.4702 - val_mrcnn_mask_loss: 0.4225\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 293s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5834 - rpn_class_loss: 0.0185 - rpn_bbox_loss: 0.0337 - mrcnn_class_loss: 0.0936 - mrcnn_bbox_loss: 0.0957 - mrcnn_mask_loss: 0.3419 - val_loss: 2.3126 - val_rpn_class_loss: 0.1966 - val_rpn_bbox_loss: 0.7280 - val_mrcnn_class_loss: 0.4717 - val_mrcnn_bbox_loss: 0.4799 - val_mrcnn_mask_loss: 0.4364\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 288s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5646 - rpn_class_loss: 0.0165 - rpn_bbox_loss: 0.0326 - mrcnn_class_loss: 0.0866 - mrcnn_bbox_loss: 0.0922 - mrcnn_mask_loss: 0.3367 - val_loss: 2.1793 - val_rpn_class_loss: 0.1713 - val_rpn_bbox_loss: 0.7179 - val_mrcnn_class_loss: 0.3827 - val_mrcnn_bbox_loss: 0.4794 - val_mrcnn_mask_loss: 0.4280\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 293s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5847 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.0379 - mrcnn_class_loss: 0.0944 - mrcnn_bbox_loss: 0.0985 - mrcnn_mask_loss: 0.3344 - val_loss: 2.3061 - val_rpn_class_loss: 0.2340 - val_rpn_bbox_loss: 0.7412 - val_mrcnn_class_loss: 0.4754 - val_mrcnn_bbox_loss: 0.4479 - val_mrcnn_mask_loss: 0.4075\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 301s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5530 - rpn_class_loss: 0.0167 - rpn_bbox_loss: 0.0298 - mrcnn_class_loss: 0.0857 - mrcnn_bbox_loss: 0.0865 - mrcnn_mask_loss: 0.3343 - val_loss: 2.2466 - val_rpn_class_loss: 0.2226 - val_rpn_bbox_loss: 0.7537 - val_mrcnn_class_loss: 0.4197 - val_mrcnn_bbox_loss: 0.4435 - val_mrcnn_mask_loss: 0.4072\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 283s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5326 - rpn_class_loss: 0.0157 - rpn_bbox_loss: 0.0279 - mrcnn_class_loss: 0.0783 - mrcnn_bbox_loss: 0.0827 - mrcnn_mask_loss: 0.3280 - val_loss: 2.4606 - val_rpn_class_loss: 0.2179 - val_rpn_bbox_loss: 0.7334 - val_mrcnn_class_loss: 0.6678 - val_mrcnn_bbox_loss: 0.4325 - val_mrcnn_mask_loss: 0.4090\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 286s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5353 - rpn_class_loss: 0.0170 - rpn_bbox_loss: 0.0299 - mrcnn_class_loss: 0.0798 - mrcnn_bbox_loss: 0.0827 - mrcnn_mask_loss: 0.3258 - val_loss: 2.5851 - val_rpn_class_loss: 0.3147 - val_rpn_bbox_loss: 0.8284 - val_mrcnn_class_loss: 0.5504 - val_mrcnn_bbox_loss: 0.4391 - val_mrcnn_mask_loss: 0.4524\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 280s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5288 - rpn_class_loss: 0.0149 - rpn_bbox_loss: 0.0332 - mrcnn_class_loss: 0.0736 - mrcnn_bbox_loss: 0.0822 - mrcnn_mask_loss: 0.3249 - val_loss: 2.6028 - val_rpn_class_loss: 0.3128 - val_rpn_bbox_loss: 0.8163 - val_mrcnn_class_loss: 0.5864 - val_mrcnn_bbox_loss: 0.4330 - val_mrcnn_mask_loss: 0.4542\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 314s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5340 - rpn_class_loss: 0.0171 - rpn_bbox_loss: 0.0359 - mrcnn_class_loss: 0.0763 - mrcnn_bbox_loss: 0.0828 - mrcnn_mask_loss: 0.3218 - val_loss: 2.4879 - val_rpn_class_loss: 0.3156 - val_rpn_bbox_loss: 0.7868 - val_mrcnn_class_loss: 0.5241 - val_mrcnn_bbox_loss: 0.4451 - val_mrcnn_mask_loss: 0.4163\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 321s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5050 - rpn_class_loss: 0.0156 - rpn_bbox_loss: 0.0325 - mrcnn_class_loss: 0.0706 - mrcnn_bbox_loss: 0.0754 - mrcnn_mask_loss: 0.3109 - val_loss: 2.5408 - val_rpn_class_loss: 0.2728 - val_rpn_bbox_loss: 0.7525 - val_mrcnn_class_loss: 0.6607 - val_mrcnn_bbox_loss: 0.4363 - val_mrcnn_mask_loss: 0.4183\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 308s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.5007 - rpn_class_loss: 0.0159 - rpn_bbox_loss: 0.0288 - mrcnn_class_loss: 0.0686 - mrcnn_bbox_loss: 0.0735 - mrcnn_mask_loss: 0.3139 - val_loss: 2.6288 - val_rpn_class_loss: 0.2800 - val_rpn_bbox_loss: 0.7705 - val_mrcnn_class_loss: 0.6988 - val_mrcnn_bbox_loss: 0.4503 - val_mrcnn_mask_loss: 0.4292\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 322s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4935 - rpn_class_loss: 0.0155 - rpn_bbox_loss: 0.0261 - mrcnn_class_loss: 0.0678 - mrcnn_bbox_loss: 0.0713 - mrcnn_mask_loss: 0.3129 - val_loss: 2.4813 - val_rpn_class_loss: 0.2937 - val_rpn_bbox_loss: 0.7554 - val_mrcnn_class_loss: 0.5744 - val_mrcnn_bbox_loss: 0.4256 - val_mrcnn_mask_loss: 0.4323\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 251s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4853 - rpn_class_loss: 0.0143 - rpn_bbox_loss: 0.0293 - mrcnn_class_loss: 0.0623 - mrcnn_bbox_loss: 0.0705 - mrcnn_mask_loss: 0.3090 - val_loss: 2.4419 - val_rpn_class_loss: 0.2082 - val_rpn_bbox_loss: 0.7163 - val_mrcnn_class_loss: 0.6048 - val_mrcnn_bbox_loss: 0.4628 - val_mrcnn_mask_loss: 0.4497\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 316s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4817 - rpn_class_loss: 0.0149 - rpn_bbox_loss: 0.0263 - mrcnn_class_loss: 0.0665 - mrcnn_bbox_loss: 0.0695 - mrcnn_mask_loss: 0.3045 - val_loss: 2.6195 - val_rpn_class_loss: 0.3116 - val_rpn_bbox_loss: 0.7933 - val_mrcnn_class_loss: 0.6230 - val_mrcnn_bbox_loss: 0.4555 - val_mrcnn_mask_loss: 0.4362\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 361s 6s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4863 - rpn_class_loss: 0.0153 - rpn_bbox_loss: 0.0292 - mrcnn_class_loss: 0.0668 - mrcnn_bbox_loss: 0.0700 - mrcnn_mask_loss: 0.3049 - val_loss: 2.6560 - val_rpn_class_loss: 0.3438 - val_rpn_bbox_loss: 0.8280 - val_mrcnn_class_loss: 0.5545 - val_mrcnn_bbox_loss: 0.4547 - val_mrcnn_mask_loss: 0.4749\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 276s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4701 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 0.0270 - mrcnn_class_loss: 0.0577 - mrcnn_bbox_loss: 0.0681 - mrcnn_mask_loss: 0.3017 - val_loss: 2.4152 - val_rpn_class_loss: 0.2346 - val_rpn_bbox_loss: 0.7686 - val_mrcnn_class_loss: 0.5478 - val_mrcnn_bbox_loss: 0.4473 - val_mrcnn_mask_loss: 0.4168\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 284s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4568 - rpn_class_loss: 0.0132 - rpn_bbox_loss: 0.0267 - mrcnn_class_loss: 0.0576 - mrcnn_bbox_loss: 0.0639 - mrcnn_mask_loss: 0.2955 - val_loss: 2.4024 - val_rpn_class_loss: 0.2444 - val_rpn_bbox_loss: 0.7848 - val_mrcnn_class_loss: 0.5203 - val_mrcnn_bbox_loss: 0.4380 - val_mrcnn_mask_loss: 0.4148\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 291s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4621 - rpn_class_loss: 0.0132 - rpn_bbox_loss: 0.0248 - mrcnn_class_loss: 0.0613 - mrcnn_bbox_loss: 0.0644 - mrcnn_mask_loss: 0.2983 - val_loss: 2.6186 - val_rpn_class_loss: 0.3226 - val_rpn_bbox_loss: 0.7999 - val_mrcnn_class_loss: 0.5844 - val_mrcnn_bbox_loss: 0.4476 - val_mrcnn_mask_loss: 0.4641\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 269s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4429 - rpn_class_loss: 0.0128 - rpn_bbox_loss: 0.0237 - mrcnn_class_loss: 0.0545 - mrcnn_bbox_loss: 0.0579 - mrcnn_mask_loss: 0.2940 - val_loss: 2.5551 - val_rpn_class_loss: 0.2343 - val_rpn_bbox_loss: 0.7424 - val_mrcnn_class_loss: 0.6858 - val_mrcnn_bbox_loss: 0.4307 - val_mrcnn_mask_loss: 0.4618\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 305s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4434 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.0298 - mrcnn_class_loss: 0.0532 - mrcnn_bbox_loss: 0.0608 - mrcnn_mask_loss: 0.2871 - val_loss: 2.6599 - val_rpn_class_loss: 0.3292 - val_rpn_bbox_loss: 0.8072 - val_mrcnn_class_loss: 0.6926 - val_mrcnn_bbox_loss: 0.4283 - val_mrcnn_mask_loss: 0.4025\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 244s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4456 - rpn_class_loss: 0.0125 - rpn_bbox_loss: 0.0272 - mrcnn_class_loss: 0.0572 - mrcnn_bbox_loss: 0.0628 - mrcnn_mask_loss: 0.2860 - val_loss: 2.6872 - val_rpn_class_loss: 0.2354 - val_rpn_bbox_loss: 0.7848 - val_mrcnn_class_loss: 0.7598 - val_mrcnn_bbox_loss: 0.4527 - val_mrcnn_mask_loss: 0.4545\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 295s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4165 - rpn_class_loss: 0.0117 - rpn_bbox_loss: 0.0245 - mrcnn_class_loss: 0.0485 - mrcnn_bbox_loss: 0.0535 - mrcnn_mask_loss: 0.2782 - val_loss: 2.5789 - val_rpn_class_loss: 0.2437 - val_rpn_bbox_loss: 0.7448 - val_mrcnn_class_loss: 0.6944 - val_mrcnn_bbox_loss: 0.4638 - val_mrcnn_mask_loss: 0.4321\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 327s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4258 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.0253 - mrcnn_class_loss: 0.0466 - mrcnn_bbox_loss: 0.0573 - mrcnn_mask_loss: 0.2849 - val_loss: 2.6797 - val_rpn_class_loss: 0.3111 - val_rpn_bbox_loss: 0.8435 - val_mrcnn_class_loss: 0.6322 - val_mrcnn_bbox_loss: 0.4301 - val_mrcnn_mask_loss: 0.4628\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 308s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3999 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.0209 - mrcnn_class_loss: 0.0450 - mrcnn_bbox_loss: 0.0518 - mrcnn_mask_loss: 0.2715 - val_loss: 2.5206 - val_rpn_class_loss: 0.2702 - val_rpn_bbox_loss: 0.7390 - val_mrcnn_class_loss: 0.5959 - val_mrcnn_bbox_loss: 0.4509 - val_mrcnn_mask_loss: 0.4647\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 273s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4110 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.0224 - mrcnn_class_loss: 0.0456 - mrcnn_bbox_loss: 0.0554 - mrcnn_mask_loss: 0.2774 - val_loss: 2.4532 - val_rpn_class_loss: 0.1925 - val_rpn_bbox_loss: 0.7170 - val_mrcnn_class_loss: 0.6396 - val_mrcnn_bbox_loss: 0.4651 - val_mrcnn_mask_loss: 0.4390\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 271s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4240 - rpn_class_loss: 0.0111 - rpn_bbox_loss: 0.0248 - mrcnn_class_loss: 0.0482 - mrcnn_bbox_loss: 0.0617 - mrcnn_mask_loss: 0.2783 - val_loss: 2.4465 - val_rpn_class_loss: 0.2375 - val_rpn_bbox_loss: 0.7689 - val_mrcnn_class_loss: 0.5308 - val_mrcnn_bbox_loss: 0.4412 - val_mrcnn_mask_loss: 0.4682\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 262s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4231 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.0260 - mrcnn_class_loss: 0.0540 - mrcnn_bbox_loss: 0.0612 - mrcnn_mask_loss: 0.2715 - val_loss: 2.5458 - val_rpn_class_loss: 0.2580 - val_rpn_bbox_loss: 0.7702 - val_mrcnn_class_loss: 0.5943 - val_mrcnn_bbox_loss: 0.4573 - val_mrcnn_mask_loss: 0.4661\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 297s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.4091 - rpn_class_loss: 0.0122 - rpn_bbox_loss: 0.0249 - mrcnn_class_loss: 0.0445 - mrcnn_bbox_loss: 0.0567 - mrcnn_mask_loss: 0.2708 - val_loss: 2.5418 - val_rpn_class_loss: 0.2397 - val_rpn_bbox_loss: 0.7936 - val_mrcnn_class_loss: 0.5716 - val_mrcnn_bbox_loss: 0.4531 - val_mrcnn_mask_loss: 0.4836\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 295s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3784 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.0196 - mrcnn_class_loss: 0.0433 - mrcnn_bbox_loss: 0.0475 - mrcnn_mask_loss: 0.2581 - val_loss: 2.7535 - val_rpn_class_loss: 0.3341 - val_rpn_bbox_loss: 0.8609 - val_mrcnn_class_loss: 0.6958 - val_mrcnn_bbox_loss: 0.4232 - val_mrcnn_mask_loss: 0.4395\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 298s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3792 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.0216 - mrcnn_class_loss: 0.0410 - mrcnn_bbox_loss: 0.0501 - mrcnn_mask_loss: 0.2562 - val_loss: 2.7493 - val_rpn_class_loss: 0.2519 - val_rpn_bbox_loss: 0.7722 - val_mrcnn_class_loss: 0.7232 - val_mrcnn_bbox_loss: 0.4411 - val_mrcnn_mask_loss: 0.5609\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 282s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3911 - rpn_class_loss: 0.0113 - rpn_bbox_loss: 0.0195 - mrcnn_class_loss: 0.0486 - mrcnn_bbox_loss: 0.0497 - mrcnn_mask_loss: 0.2621 - val_loss: 2.8714 - val_rpn_class_loss: 0.3242 - val_rpn_bbox_loss: 0.8452 - val_mrcnn_class_loss: 0.7956 - val_mrcnn_bbox_loss: 0.4457 - val_mrcnn_mask_loss: 0.4606\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 265s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3700 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.0182 - mrcnn_class_loss: 0.0426 - mrcnn_bbox_loss: 0.0452 - mrcnn_mask_loss: 0.2533 - val_loss: 2.6241 - val_rpn_class_loss: 0.2643 - val_rpn_bbox_loss: 0.8009 - val_mrcnn_class_loss: 0.6560 - val_mrcnn_bbox_loss: 0.4288 - val_mrcnn_mask_loss: 0.4741\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 271s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3567 - rpn_class_loss: 0.0091 - rpn_bbox_loss: 0.0201 - mrcnn_class_loss: 0.0334 - mrcnn_bbox_loss: 0.0450 - mrcnn_mask_loss: 0.2491 - val_loss: 2.6212 - val_rpn_class_loss: 0.2755 - val_rpn_bbox_loss: 0.7786 - val_mrcnn_class_loss: 0.7067 - val_mrcnn_bbox_loss: 0.4294 - val_mrcnn_mask_loss: 0.4310\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 295s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3723 - rpn_class_loss: 0.0114 - rpn_bbox_loss: 0.0200 - mrcnn_class_loss: 0.0399 - mrcnn_bbox_loss: 0.0459 - mrcnn_mask_loss: 0.2552 - val_loss: 2.6206 - val_rpn_class_loss: 0.2662 - val_rpn_bbox_loss: 0.7500 - val_mrcnn_class_loss: 0.6750 - val_mrcnn_bbox_loss: 0.4380 - val_mrcnn_mask_loss: 0.4914\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 264s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3741 - rpn_class_loss: 0.0089 - rpn_bbox_loss: 0.0233 - mrcnn_class_loss: 0.0382 - mrcnn_bbox_loss: 0.0461 - mrcnn_mask_loss: 0.2575 - val_loss: 2.7736 - val_rpn_class_loss: 0.2365 - val_rpn_bbox_loss: 0.7962 - val_mrcnn_class_loss: 0.7768 - val_mrcnn_bbox_loss: 0.4347 - val_mrcnn_mask_loss: 0.5294\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 266s 4s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3544 - rpn_class_loss: 0.0085 - rpn_bbox_loss: 0.0199 - mrcnn_class_loss: 0.0375 - mrcnn_bbox_loss: 0.0445 - mrcnn_mask_loss: 0.2440 - val_loss: 2.6265 - val_rpn_class_loss: 0.2603 - val_rpn_bbox_loss: 0.8133 - val_mrcnn_class_loss: 0.6161 - val_mrcnn_bbox_loss: 0.4614 - val_mrcnn_mask_loss: 0.4754\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 288s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3520 - rpn_class_loss: 0.0088 - rpn_bbox_loss: 0.0191 - mrcnn_class_loss: 0.0325 - mrcnn_bbox_loss: 0.0415 - mrcnn_mask_loss: 0.2502 - val_loss: 2.7912 - val_rpn_class_loss: 0.3335 - val_rpn_bbox_loss: 0.8362 - val_mrcnn_class_loss: 0.7082 - val_mrcnn_bbox_loss: 0.4247 - val_mrcnn_mask_loss: 0.4886\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 294s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3594 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 0.0189 - mrcnn_class_loss: 0.0344 - mrcnn_bbox_loss: 0.0434 - mrcnn_mask_loss: 0.2534 - val_loss: 2.8029 - val_rpn_class_loss: 0.2857 - val_rpn_bbox_loss: 0.7432 - val_mrcnn_class_loss: 0.8789 - val_mrcnn_bbox_loss: 0.4378 - val_mrcnn_mask_loss: 0.4572\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 309s 5s/step - batch: 30.0000 - size: 2.0000 - loss: 0.3361 - rpn_class_loss: 0.0083 - rpn_bbox_loss: 0.0180 - mrcnn_class_loss: 0.0345 - mrcnn_bbox_loss: 0.0403 - mrcnn_mask_loss: 0.2351 - val_loss: 3.0549 - val_rpn_class_loss: 0.3918 - val_rpn_bbox_loss: 0.8584 - val_mrcnn_class_loss: 0.8421 - val_mrcnn_bbox_loss: 0.4283 - val_mrcnn_mask_loss: 0.5343\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - ETA: 0s - batch: 30.0000 - size: 2.0000 - loss: 0.3261 - rpn_class_loss: 0.0083 - rpn_bbox_loss: 0.0158 - mrcnn_class_loss: 0.0315 - mrcnn_bbox_loss: 0.0384 - mrcnn_mask_loss: 0.2321"
     ]
    }
   ],
   "source": [
    "# cargar dataset de entrenamiento\n",
    "train_set = DatasetArandanos()\n",
    "train_set.load_dataset(conjunto_datos, is_train=True)\n",
    "train_set.prepare()\n",
    "\n",
    "# cargar dataset de test \n",
    "test_set = DatasetArandanos()\n",
    "test_set.load_dataset(conjunto_datos, is_train=False)\n",
    "test_set.prepare()\n",
    "\n",
    "# preparar la configuración llamando a la clase de configuración definida por el usuario\n",
    "config = ConfigArandanos()\n",
    "\n",
    "# definir el modelo\n",
    "with tf.device(config.DEVICE):\n",
    "    model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "\n",
    "# cargar pesos del modelo \n",
    "weights_path = pesos\n",
    "\n",
    "# cargar los pesos del modelo\n",
    "model.load_weights(weights_path, \n",
    "                   by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "#augmentation = iaa.Sequential(iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "#augmentation = iaa.Sometimes(5/6,iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "#augmentation = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5)])\n",
    "#augmentation = iaa.Sometimes(5/6, iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "#augmentation = iaa.Sometimes(0.5, iaa.Fliplr(0.5), iaa.Flipud(0.5))\n",
    "\n",
    "# start the training of model\n",
    "# you can change epochs and layers (head or all)\n",
    "#model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=100, layers='all', augmentation=augmentation)\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=100, layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "master.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "da38062997892a68ae88df3a1549a85ff68f4e3a875c1f51aead31b07f2af4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
